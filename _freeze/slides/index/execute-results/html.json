{
  "hash": "5575a625cad4ecfb066b789f101f652e",
  "result": {
    "markdown": "---\ntitle: \"Cleaning Medical Data<br> with R\"\nauthor: \"Crystal Lewis, Shannon Pileggi, & Peter Higgins\"\nfooter: \"[Data Cleaning](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023)\"\nlogo: \"images/R-Med-logo-revised-pride.png\"\neditor: source\nformat: \n  revealjs: \n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    chalkboard: true\nexecute:\n  echo: true\n  freeze: auto\ncache: true\n---\n# Introduction\n\n::: {.cell}\n\n:::\n\n## Licensing\n\n<br>\n\nThis work is licensed under [Creative Commons Zero v1.0 Universal](https://creativecommons.org/publicdomain/zero/1.0/).\n\n\n## Instructors\n\n::: columns\n::: {.column width=\"33%\"}\n**Crystal Lewis**\n\n![](images/Crystal_circle.png){width=\"70%\"}\n\n:::\n::: {.column width=\"33%\"}\n**Shannon Pileggi**\n\n![](images/Shannon_circle.png){width=\"70%\"}\n:::\n\n::: {.column width=\"33%\"}\n**Peter Higgins**\n\n![](images/Peter_circle.jpg){width=\"70%\"}\n\n\n\n:::\n:::\n\n## Scope\n\n![Taming the Data Beast, by Allison Horst](images/data_beast_allison_horst.jpeg)\n\nTaming the Data Beast, from Allison Horst's [Data Science Illustrations](https://allisonhorst.com/data-science-art)\n\n## Schedule\n\n| Time          | Topic           |\n|---------------|--------------------|\n|11:00 - 11:10  |   Intro/Logistics | \n|11:10 - 12:00 | Crystal Lewis (Principles of Data Management)          |\n|12:00 - 12:05 | *Break*            |\n|12:05 - 12:55 | Shannon Pileggi (Stage 1 Data Cleaning)          |\n|12:55 - 1:00 | *Break*            |\n|01:00 - 02:00 | Peter Higgins (Stage 2 Data Cleaning)          |\n\n<br>\n\nPlease add any questions to the public Zoom chat. These may be answered in the \nmoment or addressed at the end depending on context.\n\n## Exercises\n\nAll exercises can be accessed via Posit Cloud.\n\nSee [exercise instructions](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#instructions){target=\"_blank\"} for the link to access the Posit Cloud workspace.\n\n# Syntax aside\n\n## Pipes\n\n-   2014+ magrittr pipe `%>%`\n\n-   2021+ (R $\\geq$ 4.1.0) native R pipe `|>`\n\n2022 Isabella VelÃ¡squez Understanding the native R pipe \\|\\> <https://ivelasq.rbind.io/blog/understanding-the-r-pipe/>\n\n. . .\n\n<brshort>\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-2_a118722ddfe3d2b8388695b719052073'}\n\n```{.r .cell-code}\nwhatever(arg1, arg2, arg3, ...)\n\narg1 |>  \n  whatever(arg2, arg3)\n```\n:::\n\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-3_43c4b95e43ccbe6c13ab98bc0338abae'}\n\n```{.r .cell-code}\nmean(0:10)\n\n0:10 |> \n  mean()\n```\n:::\n\n:::\n:::\n\n\n::: footer\nChange `CTRL + Shift + M` shortcut to native pipe:\n\n`Tools -> Global Options -> Code -> `\n   \n&nbsp;&nbsp; `Editing -> check Use Native Pipe Operator`\n\n:::\n\n## R for Data Science: Ch 18 Pipes\n\n![](images/foo-foo.png)\n\n::: footer\n<https://r4ds.had.co.nz/pipes.html#pipes>\n:::\n\n## Namespacing\n\n`package::function()`\n\n`dplyr::select()`\n\n-   tells R explicitly to use the function `select` from the package `dplyr`\n\n-   can help to avoid name conflicts (e.g., `MASS::select()`)\n\n-   does not require `library(dplyr)`\n\n-   generally, we aimed to namespace functions from non-tidyverse packages.\n\n. . .\n\n::: columns\n::: {.column width=\"45%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-4_f17d1176be26064341febfc458f4cd7b'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nselect(mtcars, mpg, cyl) \n\nmtcars |>  \n  select(mpg, cyl) \n```\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-5_f509baf7d1120bc64763172bdfa08dd6'}\n\n```{.r .cell-code}\n# library(dplyr) not needed\n\ndplyr::select(mtcars, mpg, cyl) \n\nmtcars |>  \n  dplyr::select(mpg, cyl) \n```\n:::\n:::\n:::\n\n\n\n::: {.cell hash='index_cache/revealjs/font-awesome-color_060866e9c46e4bdee07bfe03f852bb9f'}\n\n:::\n\n# Principles of Data Management\n\n::: {.notes}\n\nWelcome to the first section of this workshop. We are going to spend the next 30 minutes or so reviewing some foundational principles of data management before we dive into writing R code.\n\n:::\n\n## Data Horror Stories\n\n::: {.r-stack}\n![](images/messy_spreadsheet1.PNG){.fragment width=\"850\" height=\"550\"}\n\n![](images/messy_spreadsheet2.PNG){.fragment width=\"650\" height=\"450\"}\n\n![](images/messy_spreadsheet3.PNG){.fragment width=\"550\" height=\"250\"}\n:::\n\n::: {.notes}\n\nSo I imagine that many of you, at some point in your career, have either created or received a spreadsheet that looks like this\n\nAnd spreadsheets formatted like this, with color coding and various headers and notes throughout CAN be really helpful when you just need to eyeball and review some information. But at some point you are probably going to need to actually analyze this data in some sort of statistical program and if you've ever tried to read a spreadsheet like this into a program like R, then you probably felt a little like this.\n\n:::\n\n## Data Horror Stories\n\n![](images/disappointment.png){fig-align=\"center\" width=90%}\n\n::: footer  \nImage from knowyourmeme.com\n:::  \n\n\n::: {.notes}\n\nMaybe a little defeated. Because you realize that while those colorful spreadsheets are formatted to be human readable, they are not formatted to be machine readable. And now you are going to have to spend hours and hours of time cleaning those spreadsheets before they can be analyzed in R. And that is what today is about. We are going to first provide you a foundational understanding for how data SHOULD be organized for analysis purposes. \n\nWe will also briefly discuss how if at all possible, you want to correct messy data at the source. \n\nAnd then last, the meat of this presentation will include a review of various R functions that will help you quickly and efficiently turn a very messy dataset into a tidy and useable one.\n\n:::\n\n## Data Organizing Principles\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n- Data Structure\n- Variable Values\n\n:::\n\n::: {.column width=\"50%\"}\n\n- Variable Types\n- Missing Data\n\n:::\n\n::::\n\n![](images/messy_data.PNG)\n\n::: {.notes}\n\nSo first we are going to talk about data organizing principles associated with 4 ideas. And by reviewing these principles, my hope is that we will all have a shared understanding of how data SHOULD be organized and that understanding will help you to strategically plan for how you should wrangle those messy datasets.\n\n:::\n\n## Data Structure\n\n1. Data should make a rectangle of rows and columns \n    - You should have the expected number of rows (cases in your data)\n    - You should have the expected number of columns (variables in your data)\n\n![](images/row_col.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnd at the intersection of those rows and columns are cells filled with values \n\nYou should have no more or no less than you expect. And when I say \"expect\", hopefully have some idea of what should exist in your data. Either you collected it yourself so you have an idea, or you have been given a codebook or data dictionary that tells you what should exist in the data.\n\n  - Extra columns in your data may mean that you have empty columns or unexpected variables\n  - Extra rows could mean you have duplicate cases or empty rows in your data  \n  - Less columns in your data means you might be missing variables  \n  - Less rows in your data means you may be missing cases  \n    \nAnd these are things that need to be remedied in our data cleaning process\n  \n:::\n\n## Data Structure\n\n2. Variable names should be the first, and **only** the first, row of your data  \n    - They should also adhere to best practices\n    - Variable names should\n      - Be unique\n      - Be meaningful (`gender` instead of `X1`)\n      - Not include spaces\n      - Not include special characters except `_`\n        - So no `/`, `-`, `!`, `\"`\n      - Not start with a number or special character\n\n::: {.notes}\n\nThe second principle regarding data structure\n\nThese aren't just arbitrary practices. They serve a purpose.\n\n  - First, they make your variable names more interpretable and easier to work with  \n  - They also make your variables more compatiable with languages such as R. For instance, R does not allow variable names to start with numbers. It will give you an error if you do this. Another example is that R also does not allow you to include dashes or hyphens in your variable names. They are consider subtraction or negation operators. So again you will get an error if you include those characters in your variable names.\n    \n:::\n\n## Exercise\n\nWhat data structure issues do you notice in our sample data?\n\n![](images/messy_data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_cbb18341\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:1em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n::: {.notes}\n\nSo let's do a quick exercise. Take one minute to review this messy data and look for any structure issues going on here. And by structure I mean review both how the rows and columns are laid out as well as variable names. If you find any errors, type them in the chat.\n\n:::\n    \n## Data Structure\n\n- Variable names are not the first row of the data\n- Our data does not make a rectangle - Empty column, empty rows\n- Variable names do not adhere to best practices\n\n![](images/structure.PNG){fig-align=\"center\"}\n\n## Variable Values\n\n1. Values should be explicit, not implicit\n    - If a blank cell is implied to be zero, fill that cell with an actual zero\n    - No color coding should be used to indicate information. Make a new variable.\n\n. . . \n\n2. Values should be analyzable. This means no more than one measure should be captured in a variable.\n\n. . .\n\n3. Variables should be captured consistently within a column\n    - Dates captured consistently (i.e. [YYYY-MM-DD](https://www.iso.org/iso-8601-date-and-time-format.html))\n    - Categories captured consistently (both spelling and capitalization)\n    - If the variable is numeric, values should fall within your expected range\n\n::: {.notes}\n\n1. We don't ever want anyone to have to guess what a cell value means\n\n- If you are color coding a variable in order to indicate treatment, instead make a treatment variable and add the values to that variable\n\n2. So for instance, we don't want both weight and height in the same variable. It would be very difficult to analyze a variable with combined information. We would want to split this information into two columns.\n\n3. Pick a format and stick to it\n\n - For instance you could make a decision to always capture dates in the international standardized format shown here which is a really nice format to work with. But whatever format you choose, make sure all dates are captured using the same format. You can click on this date in the slides to learn more about this specific format.\n\n - So if you're capturing gender, you always want to spell male the same way, always want to spell female the same way. This allows your data to be easily categorized.\n\n - So if the range for a variable is 1-50, you shouldn't see values outside of that range\n\n:::\n\n## Exercise\n\n\nWhat variable value issues do you notice in our sample data?\n\n![](images/messy_data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_61f07ecd\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:1em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n  \n## Variable Values\n\n- Color coding used to indicate information\n- Two things measured in one column\n- Categorical values captured inconsistently\n\n\n![](images/values.PNG){fig-align=\"center\"}\n\n## Variable Types\n\nVariables should be stored as your expected type (or in R terms - `class`)\n\n. . .\n\n1. **Numeric**\n    - Contain numeric values (14.5, 14.539, 789, -24)\n    - Numeric variables cannot contain special characters, spaces, or letters\n      - 100mg\n      - 83/150\n      - \" 89\"\n\n. . . \n\n2. **Date, Time, Date-Time**\n    - Represented in R as either `<date>`, `<time>` or `<dttm>`/`<POSIXct>`\n    - Allow you to perform calculations on dates\n\n::: {.notes}\n\nOr in the R world, we may refer to this as a variable class.\n\nSo let's review a few of the variable classes you might work with.\n\n1. If your variable contains non-numeric values, the class will be character. And you will no longer be able to perform calculations on your numeric variable, so no means, ranges, etc.\n\n2. Represented in R as one of these formats. Because of the way dates are stored in R, they allow you to perform calculations using your dates, which is cool. You can add dates, subtract dates, etc. So as long as your dates are stored as dates, then you are good. However, if your dates are stored as character values, you will not be able to perform calculations on your dates.\n\nIt's important to check your date types when you read in your data. While sometimes they are read in as dates, othertimes they may be read in as character values or numeric values and it's important to be aware of this.\n\n:::\n\n## Variable Types\n\n3. **Character**\n    - Contain character values or strings (\"kg\", \"R in Medicine\", \"11.5\", \"5mg\")\n          \n. . .\n\n4. **Factor**\n    - A special class of variables, helpful when working with categorical or ordinal variables\n    - Factors assign an order to your variable groups\n    - You must assign this class to your variables\n    - You can learn more about working with factors in this article: [Wrangling Categorical Data in R](https://peerj.com/preprints/3163/)\n      \n::: {.notes}\n\n3. You can even store numbers as characters. But remember, if you want to analyze those values as numeric, you will need to change them to a numeric format.\n\n4. Very useful for ordering your groups in tables, graphs, or models\n\nYou must assign this class to your variables\n\nSo when you read in your data, your character variables will not automatically be assigned as factors. You need to assign this class yourself.\n\nAnd then last, because factors can be a little tricky to understand and work with, you can learn more about working with factors in this article from Amelia McNamara and Nicholas Horton.\n\n:::\n\n\n## Exercise\n\nWhat is the R class for the following variables?\n\n::: panel-tabset\n\n### var1\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-8_71a6640e35c09622cadaf5c4b6d292a1'}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \" 7.5\" \"2\"    \"3.6\" \n```\n:::\n:::\n\n:::\n<br>\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-9_39bceb25a1b122444866d3e3e0918ab4'}\n\n```{.r .cell-code}\nclass(var1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n:::\n\n\n### var2\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-10_b06e952a48f96b4d8d2e114552e38288'}\n::: {.cell-output .cell-output-stdout}\n```\n[1] medium medium low    high   low   \nLevels: low medium high\n```\n:::\n:::\n\n:::\n<br>\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-11_62bdbc7f2fee059603a7ffe857527d06'}\n\n```{.r .cell-code}\nclass(var2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"factor\"\n```\n:::\n:::\n\n:::\n\n### var3\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-12_0a260085b30fb9b5a943fe8cb3423898'}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"50kg\" \"59kg\" \"82kg\"\n```\n:::\n:::\n\n:::\n<br>\n\n::: {.fragment}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-13_627ca7a176daa68e3a2b0cdf70d1033e'}\n\n```{.r .cell-code}\nclass(var3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n:::\n:::\n\n## Exercise\n\nWhat variable type issues do you notice in our sample data?\n\n![](images/type_clean.PNG){fig-align=\"center\" width=80% height=80%}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_97ccbbd2\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:1em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Variable Types\n\n- Dates stored as numbers\n- Text stored in numeric variables\n\n![](images/type.PNG){fig-align=\"center\"}\n\n\n## Missing Data\n\n1. Missing data should appear as you expect it to\n    - The amount of missingness\n    - The variables/cases that data is missing for\n\n. . .\n\n2. Use consistent values to indicate missing responses (Blank, NA, -999)\n    - Document your decision\n    - The missing values should match your variable type\n      - i.e., Don't use \"no response\" in a numeric variable\n      \n::: {.notes}\n\n2. So there are varying opinions on how missing data should be assigned. \n\n- Some people think that missing data should be explicitly assigned with an extreme value like -999. That way you know that the cell wasn't just skipped over by accident when data was being entered.\n\n- Some people prefer to just leave the cell blank to not cause confusion by adding extreme values to a variable.\n\nI personally have no preference for which method you use. I think it is important to be aware of the problems that can be caused by adding extreme values to your data. If you add -999 as a missing value, be aware that someone could accidentally interpret that as an actual value, leading to bad results.\n\nUltimately I think what is important though, is that you use consistent values to represent missing data (choose one and stick with it).\n\nThen, make sure your choices are documented so that future users know how to interpret the values in your data.\n\nAND last, make sure that your missing values match your variable type. If you use text to define missing values in a numeric variable, that variable will no longer be considered a numeric variable. So be aware of this.\n\n:::\n\n## Exercise\n\nWhat missing data issues do you notice in our sample data?\n\n![](images/missing_clean.PNG){fig-align=\"center\" width=75% height=70%}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_b4fdb3b3\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:1em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n    \n## Missing Data\n\n- Unexpected missing data\n- Inconsistent missing values used\n- Missing values do not match variable type\n\n![](images/missing.PNG){fig-align=\"center\"}\n\n\n## Error Reduction\n\nThe number one way to reduce data errors is to make a plan before you collect data\n\n> Correct data at the source\n\n<br>\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Plan the variables you want to collect\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Build your data collection/entry tools in a way that follows your plan\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Test your data tools before collecting/entering data\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Check your data often during data collection/entry\n\n::: {.notes}\n\nSo if you have the luxury of being able to collect your own data, you want to make sure that you spend time planning so you can correct data at the source\n\n:::\n\n## Plan the variables you want to collect\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n**Necessary to plan for**\n\n- Variable name\n- Variable label/item wording\n- Variable type\n- Allowable values/ranges\n- Missing values\n\n:::\n\n::: {.column width=\"50%\"}\n\n**Nice to plan for**\n\n- Skip patterns\n- Required items\n- Variable universe\n\n:::\n\n::::\n\n::: {.notes}\n\nThese items on the right can be really helpful to plan for if you are collecting something like survey data in particular. These items will help you better understand when and why you might have missing data for items.\n\n1. Are there skip patterns for any items? What is the logic for those items?\n2. Are items required or are people allowed to skip items?\n3. What is the variable universe for each item? Will the whole sample get each item or are some items only shown to a subsample of your group?\n\n:::\n\n## Add those variables to a data dictionary\n\n<br>\n\n::: {.cell hash='index_cache/revealjs/dictionary_b4bb4a401c2228399bcf72402b4fe3ff'}\n::: {.cell-output-display}\n```{=html}\n<div id=\"yykcbpacnd\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#yykcbpacnd table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#yykcbpacnd thead, #yykcbpacnd tbody, #yykcbpacnd tfoot, #yykcbpacnd tr, #yykcbpacnd td, #yykcbpacnd th {\n  border-style: none;\n}\n\n#yykcbpacnd p {\n  margin: 0;\n  padding: 0;\n}\n\n#yykcbpacnd .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#yykcbpacnd .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yykcbpacnd .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yykcbpacnd .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yykcbpacnd .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yykcbpacnd .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yykcbpacnd .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yykcbpacnd .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yykcbpacnd .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#yykcbpacnd .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#yykcbpacnd .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yykcbpacnd .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yykcbpacnd .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yykcbpacnd .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yykcbpacnd .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yykcbpacnd .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#yykcbpacnd .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#yykcbpacnd .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#yykcbpacnd .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yykcbpacnd .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#yykcbpacnd .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yykcbpacnd .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yykcbpacnd .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yykcbpacnd .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yykcbpacnd .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yykcbpacnd .gt_left {\n  text-align: left;\n}\n\n#yykcbpacnd .gt_center {\n  text-align: center;\n}\n\n#yykcbpacnd .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yykcbpacnd .gt_font_normal {\n  font-weight: normal;\n}\n\n#yykcbpacnd .gt_font_bold {\n  font-weight: bold;\n}\n\n#yykcbpacnd .gt_font_italic {\n  font-style: italic;\n}\n\n#yykcbpacnd .gt_super {\n  font-size: 65%;\n}\n\n#yykcbpacnd .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#yykcbpacnd .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#yykcbpacnd .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#yykcbpacnd .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#yykcbpacnd .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#yykcbpacnd .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#yykcbpacnd .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"var_name\">var_name</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\">label</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"type\">type</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"values\">values</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"missing_values\">missing_values</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"var_name\" class=\"gt_row gt_left\">pat_id</td>\n<td headers=\"label\" class=\"gt_row gt_left\">Patient Identifier</td>\n<td headers=\"type\" class=\"gt_row gt_left\">character</td>\n<td headers=\"values\" class=\"gt_row gt_left\">001-030</td>\n<td headers=\"missing_values\" class=\"gt_row gt_left\">NA</td></tr>\n    <tr><td headers=\"var_name\" class=\"gt_row gt_left\">treatment</td>\n<td headers=\"label\" class=\"gt_row gt_left\">Treatment for UC</td>\n<td headers=\"type\" class=\"gt_row gt_left\">character</td>\n<td headers=\"values\" class=\"gt_row gt_left\">upa; uste; oza</td>\n<td headers=\"missing_values\" class=\"gt_row gt_left\">NA</td></tr>\n    <tr><td headers=\"var_name\" class=\"gt_row gt_left\">start_date</td>\n<td headers=\"label\" class=\"gt_row gt_left\">Date of start of treatment</td>\n<td headers=\"type\" class=\"gt_row gt_left\">date</td>\n<td headers=\"values\" class=\"gt_row gt_left\">YYYY-MM-DD</td>\n<td headers=\"missing_values\" class=\"gt_row gt_left\">NA</td></tr>\n    <tr><td headers=\"var_name\" class=\"gt_row gt_left\">ethnic</td>\n<td headers=\"label\" class=\"gt_row gt_left\">Ethnicity - hispanic or not hispanic</td>\n<td headers=\"type\" class=\"gt_row gt_left\">character</td>\n<td headers=\"values\" class=\"gt_row gt_left\">hispanic; not hispanic</td>\n<td headers=\"missing_values\" class=\"gt_row gt_left\">missing</td></tr>\n    <tr><td headers=\"var_name\" class=\"gt_row gt_left\">start_mes</td>\n<td headers=\"label\" class=\"gt_row gt_left\">Mayo endoscopic Score at start of treatment</td>\n<td headers=\"type\" class=\"gt_row gt_left\">numeric</td>\n<td headers=\"values\" class=\"gt_row gt_left\">0-3</td>\n<td headers=\"missing_values\" class=\"gt_row gt_left\">-99</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n::: {.notes}\n\nA data dictionary is a rectangular formatted collection of names, definitions, and attributes about variables in a dataset\n\nSet this up similar to a dataset, with a row and column layout, with variable names in first row\n\n:::\n\n## Build your tools based on your data dictionary\n\n- Excel\n- Qualtrics\n- REDCap\n\n- Know the strengths and limitations of your tool\n  - Consider things such a privacy (PHI), versioning, validation\n  - [Tidy Spreadsheets in Medical Research (70 mins)](https://www.youtube.com/watch?v=9f-hpJbjKZo&t=7s)\n  \n::: {.notes}\n\nAnd by tool I mean whatever program you use to collect or enter data. So that could be Excel, RedCap, Qualtrics, or something else. Not all data entry and collection tools are created equal so make sure to consider the limitations and strengths of your tools. \n\nConsider how your tool handles things like data security and privacy, versioning, and data validation. \n\nWe are not going to explore different data collection and entry tools today but if you want to learn more about the strengths and weaknesses of various tools, specifically if you want to learn the limitations of using Excel as a data collection tool, you can watch this video from a previous R in Medicine workshop.\n\n:::\n  \n## Build your tools based on your data dictionary\n\n. . . \n\n<br>\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Name your variables correctly in your tool  \n\n- Instead of Q1, Q2, Q3 -> id, start_date, treatment\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Build items to only accept allowable values\n\n-   Only within specified range (0-50)\n-   Only within specified categories (\"hispanic\", \"not hispanic\")\n\n. . .\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 448 512\" style=\"height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#7090A5;overflow:visible;position:relative;\"><path d=\"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"/></svg>`{=html} Build items to only accept specified variable types\n\n-   Only numeric values\n-   Only dates in the YYYY-MM-DD format\n\n::: {.notes}\n\nSo once you've chosen your tool, you want to build your data collection/entry screens based on your data dictionary\n\n1. This reduces confusion during data entry, and also creates less data cleaning steps when you export your data\n\n2. If working with numeric items, only allow values in a specified range, for example 0-50. You can set these validation rules in your tools, so that if someone tries to enter 51, it will say, this value is not allowed\n\nIf working with categorical items, only allow values in specified categories. Here it can be really helpful to use something like a drop down menu instead of open text boxes to make sure you own collect allowable values only.\n\n3. Again, you can set these content validation rules in your tools so that a warning will pop up when unexpected formats or types are entered\n\n:::\n\n## Test your data collection or entry tool\n\n- Collect/enter sample data\n  - Are any items missing?\n  - Are you getting unexpected values for items?\n    - Values out of range\n    - Incorrect formats\n    - Inconsistent entries\n      - \"m\", \"male\", \"Male\", \"MALE\"\n  - Is the skip logic working as expected?\n  - Are people able to skip items that they should not be able to skip?\n  \n::: {.notes}\n\nIf you find anything wrong, fix this in your tool before you begin to collect or enter data\n\n:::\n\n\n## Review your data often during data collection or entry\n\n1. Validate your data based on your expectations\n    - `pointblank`\n    - `validate`\n    - `assertr`\n    - `dataquieR`\n    - Excellent resource: [Data Validation in R: From Principles to Tools and Packages (80 minutes)](https://www.youtube.com/watch?v=0d1c-8yw6Tk)\n    \n::: {.notes}\n\nOne option for reviewing your data is to write code in a program such as R, to validate your specified criteria. You can write code to validate that variables are your expected types, fall within expected ranges, ids are not duplicated and so forth.\n\nHere are a couple of R packages that have functions specifically for validation purposes and they export really helpful reports for you to review. There will actually be a presentation during this conference on the last package on this list. I believe on Thursday at 3 Eastern Time. \n\nThis is a link to a great talk on validation that reviews all of these packages and more. I highly recommend watching it.\n\n:::\n\n## `pointblank` report\n\n::: panel-tabset\n\n## Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-16_e71527d6972b489882de62bf1a5b8a68'}\n\n:::\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-17_f6e8059e0dd30cde2313ab80bd3eb3ed'}\n\n```{.r .cell-code}\nlibrary(pointblank)\n\n# Import my data\n\ndf_raw <- readxl::read_excel(\"data/mydata.csv\")\n\n# Check my assumptions\n\ncreate_agent(df_raw) |>\n  rows_distinct(columns = vars(pat_id)) |>\n  col_vals_not_null(columns = vars(pat_id)) |>\n  col_is_date(columns = vars(start_date)) |>\n  col_is_numeric(columns = vars(start_mes)) |>\n  col_vals_in_set(columns = vars(treatment), set = c(\"upa\", \"uste\", \"oza\")) |>\n  col_vals_in_set(columns = vars(ethnic), set = c(\"hispanic\", \"not hispanic\")) |>\n  col_vals_between(columns = vars(start_mes), left = 0, right = 3, na_pass = FALSE) |>\n  interrogate()\n```\n:::\n\n## Report\n\n![](images/pointblank.PNG){fig-align=\"center\" width=80% height=90%}\n\n:::\n\n::: {.notes}\n\nSo here I am showing a very brief example of how I might set up some validation criteria using the pointblank package. And I could run this on a recurring schedule during data collection or entry to make sure everything is being collected as expected.\n\nAnd when I run this code, I receive this report that assures me that everything is being collected as expected EXCEPT there are two variables that fail. My start_date variable is not being collected in a date format and my ethnicity variable has collected some unexpected values. And this is something that if caught early, I could go and fix in my tool. Because if I don't fix this, I could end up with really messy data, or I might end up with data that is completely unusable if there are some values collected that I am unable to interpret.\n\n:::\n\n## Review your data often during data collection\n\n2. Create a codebook to review univariate summary statistics\n    - `codebookr`\n    - `codebook`\n    - `memisc`\n    - `sjPlot`\n    \n::: {.notes}\n\nA second option for reviewing your data during collection is to create a codebook. Codebooks provide descriptive variable-level information as well univariate summary statistics (such as means, ranges, counts). There are several R packages that automate the creation of codebooks. I'm showing 4 here but there are more.\n\nBut unlike validation, where we write code based on individualized criteria, for the most part, these codebooks provide similar out of the box summary statistics that allow you to get a feel for what is going on in your data. \n\nBoth the validation and codebook methods provide you solid information to help you better understand if your data is being collected as expected.\n\n:::\n\n## `codebookr` codebook\n\n::: panel-tabset\n\n## Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-18_b0310d0d02c77d991b49272f0983f0cb'}\n\n```{.r .cell-code}\nlibrary(codebookr)\n\n# Import my data\n\ndf_raw <- readxl::read_excel(\"data/mydata.csv\")\n\n# Create my codebook\n\ndf_codebook <- codebook(df_raw)\n\nprint(df_codebook,\"my_codebookr_codebook.docx\")\n```\n:::\n\n## Codebook\n\n![](images/codebook.PNG){fig-align=\"center\" width=85%}\n\n\n:::\n\n::: {.notes}\n\nHere is one example of a codebook created using the codebookr package. And if I ran that code, you can see it gives me a codebook that looks like this.\n\nAt the top it provides me some overarching dataset summary information and then it quickly jumps into variable-level information including summary statistics.\n\nAnd I could once again see here that I am having issues with my start_date variable, it's being collected as a numeric type instead of a date. And my ethnicity variable has some unexpected values. And I would want to go correct this at the source so I can fix this issue sooner rather than later.\n\nAnd the last thing to know about codebooks is that they are even more useful when working with data that contains embedded metadata (like variable and value labels - you see in this in data that comes from programs like SPSS or Stata). When working with labelled data, those labels are displayed in the codebook. So for instance, if the data were labelled, you would see variable descriptions under each variable section, that describes what each variable represents. So for instance, under pat_id, you would see a label that says \"patient unique identifier\". And that descriptive information helps me to better interpret the data. But as you can see, codebooks work fine without labels as well.\n\n:::\n\n# Data Cleaning Practices\n\n::: {.notes}\n\nSo all of those practices we just covered are obviously done in an ideal world, where we have autonomy over how data is collected. But there are obviously still going to be situations where you are handed data that you had no control over the collection/entry process.\n\nOr maybe, even if you did collect your own data, despite your best efforts to collect/enter clean data, you still ended up with data that contains errors\n\nFor the remainder of this workshop we will be working through a sample messy dataset to both identify and resolve issues to leave us with a usable tidy dataset that is ready for analysis.\n\n:::\n\n## Scenario\n\n- We have data that originate from an observational study comparing 3 treatments of ulcerative colitis (UC)\n\n- We have an analysis question:\n  - Are there differences in change in MES and QOL scores between start and finish, and are the decreases in scores greater for any of the 3 new medications?\n  \n- In order to answer this question, we have asked a student to extract data from the medical record into Excel\n\n- Along with the spreadsheet, we are provided a data dictionary\n\n- As we start to review the data, we find a sundry of errors that need correction\n\n\n## Exercise\n\n\nTake 5 minutes to review the data dictionary and our data.\n\n1. Log in to Posit Cloud and navigate to our project\n2. Open the data folder and open the file \"messy_uc.xlsx\"\n\n:::: {layout=\"[[45,-10,45], [100]]\"}\n::: {.column}\n![](images/data_file.PNG){width=80%}\n:::\n\n::: {.column}\n-   When you finish, give us a ðŸ‘\n\n-   If you are having trouble, give us a âœ‹\n:::\n::::\n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_0a61099a\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n::: {.notes}\n\nSo we have this scenario. And believe it or not, we are not going to jump into reading the data into R just yet. The first thing we really should do is open the Excel file to review both the data AND the data dictionary. While it seems low-tech, it is actually really important to learn what you are getting into before reading your file into R.\n\nSo both the data and data dictionary are in the same file. So let's take 5 minutes to log into posit cloud and navigate to our project and then to our data file. Then open and review both the data dictionary and the data to see what is actually going on in our file.\n\nThroughout this workshop, when you finish with an exercise, go ahead and give us the thumbs up using the Zoom reactions. If you are having trouble with an exercise, give us a hand wave.\n\n....\n\nSo hopefully you noticed a few things upon reviewing our data.\n\n1. Our variable names are not the first row of our data. There are 6 rows of irrelevant information before we finally get to our variable names. That is really important to know before we try to import our data.\n\n2. Our data is not the first sheet of our Excel file. It's actually the 3rd sheet over. And that's also important to know.\n\n:::\n\n## Import our file\n\n- We are going to use the `read_excel()` function from the `readxl` package\n\n- There are several arguments to consider when using this function\n  - path\n  - sheet = NULL\n  - col_names = TRUE\n  - na = \" \"\n  - skip = 0\n\n- type `?read_excel` in your console to see more arguments\n\n::: {.notes}\n\nSo now we are ready to import our data into R\n\nThe first thing we would want to do is open an R script, or it could also be a rmarkdown or quarto file\n\nWe are going to use...\n\n- list the path to our xlsx file\n- we can add the name or position of the sheet to read in\n- should R grab column names from the first row in your data?\n- are there any values that R should read in as NA? For instance, if we had added -999 as our missing values indicator, we could tell R to convert all of our -999s to NA when we read the data in\n- what is the minimum number of rows R should skip before reading anything?\n\n:::\n\n## Import our file\n\n::: panel-tabset\n\n## Script\n\n![](images/script2.PNG){width=50%}\n\n## Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-20_f293430756b5bdbc91b3cf3330db2083'}\n\n```{.r .cell-code}\nlibrary(readxl)\n\n# Import our file\n\ndf_raw <- readxl::read_excel(\"data/messy_uc.xlsx\",\n  sheet = \"__\", \n  skip = __\n)\n```\n:::\n\n\n## Data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-21_16dc92271edd5333eac1a3a88762d451'}\n\n:::\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-22_77e27571642495dba045e3f44e78a6f8'}\n::: {.cell-output-display}\n```{=html}\n<div id=\"hgowbrklrl\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#hgowbrklrl table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#hgowbrklrl thead, #hgowbrklrl tbody, #hgowbrklrl tfoot, #hgowbrklrl tr, #hgowbrklrl td, #hgowbrklrl th {\n  border-style: none;\n}\n\n#hgowbrklrl p {\n  margin: 0;\n  padding: 0;\n}\n\n#hgowbrklrl .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#hgowbrklrl .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#hgowbrklrl .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#hgowbrklrl .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#hgowbrklrl .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#hgowbrklrl .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#hgowbrklrl .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#hgowbrklrl .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#hgowbrklrl .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#hgowbrklrl .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#hgowbrklrl .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hgowbrklrl .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#hgowbrklrl .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#hgowbrklrl .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#hgowbrklrl .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hgowbrklrl .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#hgowbrklrl .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#hgowbrklrl .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#hgowbrklrl .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hgowbrklrl .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#hgowbrklrl .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hgowbrklrl .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#hgowbrklrl .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hgowbrklrl .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hgowbrklrl .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hgowbrklrl .gt_left {\n  text-align: left;\n}\n\n#hgowbrklrl .gt_center {\n  text-align: center;\n}\n\n#hgowbrklrl .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#hgowbrklrl .gt_font_normal {\n  font-weight: normal;\n}\n\n#hgowbrklrl .gt_font_bold {\n  font-weight: bold;\n}\n\n#hgowbrklrl .gt_font_italic {\n  font-style: italic;\n}\n\n#hgowbrklrl .gt_super {\n  font-size: 65%;\n}\n\n#hgowbrklrl .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#hgowbrklrl .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#hgowbrklrl .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#hgowbrklrl .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#hgowbrklrl .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#hgowbrklrl .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#hgowbrklrl .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"pat_id\">pat_id</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"treatment\">treatment</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"start_date\">start_date</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"ethnic\">ethnic</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"race\">race</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"dob\">dob</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"...7\">...7</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"start_bp\">start_bp</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"pre/post_wt_kg\">pre/post_wt_kg</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"start_mes\">start_mes</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">001</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">upa</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44208</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Caucasian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">2005-01-07</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">114/72</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">84/82</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">002</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">uste</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44215</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Caucasian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1937-04-13</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">132/86</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">77/77</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">003</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">oza</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44230</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">African-American</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1946-06-06</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">124/92</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">74/75</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">1</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">004</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">upa</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44245</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Caucasian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1963-07-14</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">144/83</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">66/65</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">005</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">oza</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44255</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Mixed</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1978-05-12</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">122/78</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">55/56</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">006</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">uste</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44259</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Other</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1992-04-03</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">121/80</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">111/110</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">007</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">uste</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44264</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">not hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Asian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1955-08-22</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">133/74</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">133/130</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">008</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">oza</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44999</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">Hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">afromerican</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1974-09-11</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">116/73</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">74/76</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">009</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">upa</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44276</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">NOT hispanic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Caucasian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1984-11-14</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">118/66</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">82/80</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">2</td></tr>\n    <tr><td headers=\"pat_id\" class=\"gt_row gt_right\">010</td>\n<td headers=\"treatment\" class=\"gt_row gt_left\">oza</td>\n<td headers=\"start_date\" class=\"gt_row gt_right\">44278</td>\n<td headers=\"ethnic\" class=\"gt_row gt_left\">hispamnic</td>\n<td headers=\"race\" class=\"gt_row gt_left\">Caucasian</td>\n<td headers=\"dob\" class=\"gt_row gt_right\">1972-12-20</td>\n<td headers=\"...7\" class=\"gt_row gt_center\">NA</td>\n<td headers=\"start_bp\" class=\"gt_row gt_right\">122/78</td>\n<td headers=\"pre/post_wt_kg\" class=\"gt_row gt_right\">85/87</td>\n<td headers=\"start_mes\" class=\"gt_row gt_right\">3</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n:::\n\n::: {.notes}\n\nSo as I mentioned before, the very first thing we would do is open our script, or our Rmarkdown or quarto file, so that we can save our code as we write it. So your RStudio pane would look something like this. \n\nAnd then we would use the read_excel function to read in our data\n\nNotice that I am giving you a hint here that in this situation we want to use both the sheet and the skip arguments. I am not showing you the full code because we are going to do this in an exercise here in just a moment. But do pay attention to the quotation marks that are needed for the sheet argument. Those are not needed for the skip argument.\n\n:::\n\n## Exercise (CL1)\n\n<br>\n\nYour turn! Take 3 minutes to import the data.\n\n1. Open \"exercises.qmd\" in our Posit Cloud project\n2. Navigate to ## CL1\n3. Update the code and run the code chunk using the green arrow\n\n<br>\n\n[--> Take me to the exercises <--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#cl1){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_06cc35e9\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n::: {.notes}\n\nYou'll want to find and open the pre-loaded quarto file called exercises.qmd.\n\n::: \n\n## Review the data\n\n> EDA is not a formal process with a strict set of rules. More than anything, EDA is a state of mind. During the initial phases of EDA you should feel free to investigate every idea that occurs to you. \n*- R for Data Science*\n\n![](https://media.giphy.com/media/lXu72d4iKwqek/giphy.gif){fig-align=\"center\" width=80%}\n\n::: footer  \nImage from giphy.com\n:::  \n\n\n::: {.notes}\n\nNow that we've imported our data, it's time to start reviewing the data\n\nTo quote the authors of R 4 Data Science\n\nOr data exploration\n\nSo what does this mean? It means there is no one prescriptive way to review your data. There are endless ways to figure out if there are errors in your data. Try any ideas you can think of. With that said, there are still some common steps you can at least start with.\n\n:::\n\n## Review the data\n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\nGet to know your data  \n\n  - How many rows? How many columns?\n  - What are the variable types?\n  - What are variable values?\n  - How much missing data is there?\n  - How are variables related?\n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\nThere are several functions that can be used to explore data\n\n- `dplyr::glimpse()`\n- `skimr::skim()`\n- `base::summary()`\n- `visdat:vis_dat()`\n- `summarytools::dfSummary()`\n- `DataExplorer::create_report()`\n- `Hmisc::describe()`\n\n:::\n\n::::\n\n::: {.notes}\n\nSo after you read your data into R, once again, first, use the old fashioned method of opening up your data and looking at it to see if everything imported as you expected.\n\nAfter that, you can start to run some functions to review your data for the following things.\n\n3\\. Are the values within your expected ranges? What outliers do you see? Is there a lack of variation?\n\n5\\. Consider bivariate plots, is one variable high and the other low - is that normal\n\nHere are 7 examples\n\n\n:::\n\n\n## `summarytools::dfSummary()`\n\n::: panel-tabset\n\n## Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-24_2def976084380109bbf4aa97904ac47b'}\n\n```{.r .cell-code}\nlibrary(summarytools)\n\n# Review our data\n\ndfSummary(df_raw)\n```\n:::\n\n:::{.notes}\n\nHere is an example of exploring our data using the dfSummary() function\n\nSo this function provides some overall summary information (number of rows and columns) as well as variable level summary information including variable type, values, frequencies, and histograms.\n\n:::\n\n## Output\n\n![](images/exploratory1.PNG){width=50%}![](images/exploratory2.PNG){width=50% height=90%}\n\n:::\n\n## `skimr::skim()`\n\n::: panel-tabset\n\n## Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-25_fbbf867405387e65c2671d96f8668f2b'}\n\n```{.r .cell-code}\nlibrary(skimr)\n\n# Review our data\n\nskim(df_raw)\n```\n:::\n\n## Output\n\n![](images/skimr.PNG){width=90%}\n\n:::\n\n:::{.notes}\n\nHere's another example of exploring our data, this time using the `skim()` function\n\nSo this function provides similar information to dfSummary, just formatted differently. It also provides some overall data summary information (number of rows and columns) as well as variable level summary information including variable type, completion rate, values, percentiles, and histograms. \n\nBut a quick clarification about this function. You'll notice that it provides a min and max value. This is actually the min and max character count for each variable. So while this may be a little confusing at first, this actually can be really helpful information.\n\n:::\n\n## Exercise (CL2)\n\nUse one or more of these exploratory packages to review your data. What fixes do you see that need to happen?\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n- `dplyr::glimpse()`\n- `skimr::skim()`\n- `base::summary()`\n- `visdat:vis_dat()`\n\n:::\n\n::: {.column width=\"40%\"}\n- `summarytools::dfSummary()`\n- `DataExplorer::create_report()`\n- `Hmisc::describe()`\n:::\n\n::::\n\n<br>\n\n[--> Take me to the exercises <--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#cl2){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_f3852b5f\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n\n\n# Stage 1<br> Data Cleaning\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-27_51181fc5c7ef2190a40b57f2d29f4da2'}\n\n:::\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-28_aca5f42bb8f6d766de689848ef386645'}\n\n:::\n\n## Variable names\n\nOriginal variable names in excel:\n\n![](images/var_names_1.PNG)\n\n. . .\n\n<br>\n\nVariable names import as shown, with modifications from `readxl::read_excel()` to ensure uniqueness:\n\n![](images/var_names_2.PNG)\n\n## Variable names, cleaner\n\nVariable names as imported:\n\n![](images/var_names_2.PNG)\n\n. . .\n\n<br>\n\n`janitor::clean_names()` removes special characters and implements snake case by default:\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-29_8904c293767eaf47b0d6ac22f96dcddd'}\n\n```{.r .cell-code}\ndf_clean <- df_raw |> \n  janitor::clean_names() \n```\n:::\n\n![](images/var_names_3.PNG)\n\n## Remove empty columns or rows\n\n::: panel-tabset\n### Problem\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-30_6dc1793bc9a24f7c16b1db7aaff73bf3'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(pat_id, race:start_bp) |> \n  slice(13:18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 5\n  pat_id race             dob                 x7    start_bp\n  <chr>  <chr>            <dttm>              <lgl> <chr>   \n1 013    Caucasian        1948-02-27 00:00:00 NA    118/73  \n2 014    African-American 1966-04-22 00:00:00 NA    106/59  \n3 015    H/API            1978-08-11 00:00:00 NA    112/69  \n4 <NA>   <NA>             NA                  NA    <NA>    \n5 016    African-American 1998-10-28 00:00:00 NA    114/76  \n6 017    Caucasian        2001-01-09 00:00:00 NA    124/80  \n```\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-31_ef561f9e4c79ddc398e2cc1fd4c512c5'}\n\n```{.r .cell-code  code-line-numbers=\"3\"}\ndf_clean <- df_raw |> \n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\"))\n```\n:::\n\n<br>\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-32_9dd440f8627ef6e94ce581f6ac57caf9'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(pat_id, race:start_bp) |> \n  slice(13:18)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 4\n  pat_id race             dob                 start_bp\n  <chr>  <chr>            <dttm>              <chr>   \n1 013    Caucasian        1948-02-27 00:00:00 118/73  \n2 014    African-American 1966-04-22 00:00:00 106/59  \n3 015    H/API            1978-08-11 00:00:00 112/69  \n4 016    African-American 1998-10-28 00:00:00 114/76  \n5 017    Caucasian        2001-01-09 00:00:00 124/80  \n6 018    Caucasian        1994-03-07 00:00:00 120/68  \n```\n:::\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"35%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-33_5507ce838f641ea8d789c8056216057d'}\n\n```{.r .cell-code}\n#\ndf_raw |>\n  janitor::clean_names() |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 31\nColumns: 38\n$ pat_id                           <chr> \"001\", \"002\", \"003\", \"004\", \"005\", \"0â€¦\n$ treatment                        <chr> \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"â€¦\n$ start_date                       <dbl> 44208, 44215, 44230, 44245, 44255, 44â€¦\n$ ethnic                           <chr> \"hispanic\", \"not hispanic\", \"not hispâ€¦\n$ race                             <chr> \"Caucasian\", \"Caucasian\", \"African-Amâ€¦\n$ dob                              <dttm> 2005-01-07, 1937-04-13, 1946-06-06, â€¦\n$ x7                               <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, Nâ€¦\n$ start_bp                         <chr> \"114/72\", \"132/86\", \"124/92\", \"144/83â€¦\n$ pre_post_wt_kg                   <chr> \"84/82\", \"77/77\", \"74/75\", \"66/65\", \"â€¦\n$ start_mes                        <dbl> 3, 2, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3â€¦\n$ start_bss                        <dbl> 75.45589, 53.62239, 25.52527, 79.3659â€¦\n$ start_abd_score                  <dbl> 80.59025, 53.64479, 26.15548, 77.9491â€¦\n$ start_sys                        <dbl> 81.45415, 52.60911, 27.55523, 79.8218â€¦\n$ start_coping                     <dbl> 50.41090, 29.56833, 15.20377, 51.2653â€¦\n$ start_emo                        <dbl> 73.32378, 55.72461, 36.56135, 80.7601â€¦\n$ daily_life_impact_score_at_start <dbl> 86.88945, 56.10371, 31.38942, 84.8523â€¦\n$ start_wbc                        <dbl> 8.2, 10.1, 5.5, 4.7, 8.9, 9.3, 5.6, 9â€¦\n$ start_plt                        <chr> \"273K/microL\", \"414K/microL\", \"323K/mâ€¦\n$ start_na                         <chr> \"137mmol/L\", \"142mmol/L\", \"140mmol/L\"â€¦\n$ start_k                          <chr> \"3.7\", \"4.0999999999999996\", \"4.3\", \"â€¦\n$ end_month                        <dbl> 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9â€¦\n$ end_day                          <dbl> 14, 21, 6, 22, 30, 4, 10, 15, 22, 26,â€¦\n$ end_year                         <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2â€¦\n$ end_mes                          <dbl> 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 1â€¦\n$ end_bss                          <dbl> 9.455894, 31.622388, 25.525267, 35.36â€¦\n$ end_abd                          <dbl> 20.590252, 33.644791, 26.155480, 37.9â€¦\n$ end_sys                          <dbl> 9.454153, 28.609114, 27.555232, 31.82â€¦\n$ end_coping                       <dbl> 23.41090, 20.56833, 15.20377, 33.2653â€¦\n$ end_emo                          <chr> \"31.980531232702354\", \"43.15496159247â€¦\n$ end_dl                           <chr> \"6.6605585857717573\", \"30.53917899804â€¦\n$ end_wbc                          <dbl> 8.562208, 11.135466, 3.000000, 5.6919â€¦\n$ end_plt                          <dbl> 201, 340, 256, 327, 432, 348, 181, 12â€¦\n$ end_na                           <dbl> 137.3278, 142.2140, 140.0831, 139.158â€¦\n$ end_k                            <dbl> 3.741212, 4.148464, 4.471147, 3.64134â€¦\n$ fake_street                      <chr> \"990Â MohammadÂ Mountain\", \"8512Â O'Connâ€¦\n$ fake_city                        <chr> \"NorthÂ Sigmundville\", \"PortÂ Halstad\",â€¦\n$ fake_state                       <chr> \"NewÂ Mexico\", \"Missouri\", \"SouthÂ Caroâ€¦\n$ fake_zip                         <dbl> 96074, 11264, 57246, 31457, 30711, 52â€¦\n```\n:::\n:::\n:::\n\n::: {.column width=\"65%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-34_7dc19f0d83d0b61ec779e90bdd030b7d'}\n\n```{.r .cell-code}\ndf_raw |> \n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 37\n$ pat_id                           <chr> \"001\", \"002\", \"003\", \"004\", \"005\", \"0â€¦\n$ treatment                        <chr> \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"â€¦\n$ start_date                       <dbl> 44208, 44215, 44230, 44245, 44255, 44â€¦\n$ ethnic                           <chr> \"hispanic\", \"not hispanic\", \"not hispâ€¦\n$ race                             <chr> \"Caucasian\", \"Caucasian\", \"African-Amâ€¦\n$ dob                              <dttm> 2005-01-07, 1937-04-13, 1946-06-06, â€¦\n$ start_bp                         <chr> \"114/72\", \"132/86\", \"124/92\", \"144/83â€¦\n$ pre_post_wt_kg                   <chr> \"84/82\", \"77/77\", \"74/75\", \"66/65\", \"â€¦\n$ start_mes                        <dbl> 3, 2, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3â€¦\n$ start_bss                        <dbl> 75.45589, 53.62239, 25.52527, 79.3659â€¦\n$ start_abd_score                  <dbl> 80.59025, 53.64479, 26.15548, 77.9491â€¦\n$ start_sys                        <dbl> 81.45415, 52.60911, 27.55523, 79.8218â€¦\n$ start_coping                     <dbl> 50.41090, 29.56833, 15.20377, 51.2653â€¦\n$ start_emo                        <dbl> 73.32378, 55.72461, 36.56135, 80.7601â€¦\n$ daily_life_impact_score_at_start <dbl> 86.88945, 56.10371, 31.38942, 84.8523â€¦\n$ start_wbc                        <dbl> 8.2, 10.1, 5.5, 4.7, 8.9, 9.3, 5.6, 9â€¦\n$ start_plt                        <chr> \"273K/microL\", \"414K/microL\", \"323K/mâ€¦\n$ start_na                         <chr> \"137mmol/L\", \"142mmol/L\", \"140mmol/L\"â€¦\n$ start_k                          <chr> \"3.7\", \"4.0999999999999996\", \"4.3\", \"â€¦\n$ end_month                        <dbl> 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9â€¦\n$ end_day                          <dbl> 14, 21, 6, 22, 30, 4, 10, 15, 22, 26,â€¦\n$ end_year                         <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2â€¦\n$ end_mes                          <dbl> 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 1â€¦\n$ end_bss                          <dbl> 9.455894, 31.622388, 25.525267, 35.36â€¦\n$ end_abd                          <dbl> 20.590252, 33.644791, 26.155480, 37.9â€¦\n$ end_sys                          <dbl> 9.454153, 28.609114, 27.555232, 31.82â€¦\n$ end_coping                       <dbl> 23.41090, 20.56833, 15.20377, 33.2653â€¦\n$ end_emo                          <chr> \"31.980531232702354\", \"43.15496159247â€¦\n$ end_dl                           <chr> \"6.6605585857717573\", \"30.53917899804â€¦\n$ end_wbc                          <dbl> 8.562208, 11.135466, 3.000000, 5.6919â€¦\n$ end_plt                          <dbl> 201, 340, 256, 327, 432, 348, 181, 12â€¦\n$ end_na                           <dbl> 137.3278, 142.2140, 140.0831, 139.158â€¦\n$ end_k                            <dbl> 3.741212, 4.148464, 4.471147, 3.64134â€¦\n$ fake_street                      <chr> \"990Â MohammadÂ Mountain\", \"8512Â O'Connâ€¦\n$ fake_city                        <chr> \"NorthÂ Sigmundville\", \"PortÂ Halstad\",â€¦\n$ fake_state                       <chr> \"NewÂ Mexico\", \"Missouri\", \"SouthÂ Caroâ€¦\n$ fake_zip                         <dbl> 96074, 11264, 57246, 31457, 30711, 52â€¦\n```\n:::\n:::\n:::\n:::\n:::\n\n## Recoding\n\n::: panel-tabset\n### Problem\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-35_f7312c46af93a4750de98adc272f9407'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(ethnic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã— 2\n  ethnic           n\n  <chr>        <int>\n1 Hispanic         1\n2 NOT hispanic     1\n3 hispamnic        1\n4 hispanic         3\n5 not hispanic    24\n```\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-36_d876e91950a9b1b0091ec96b8cd4b7f7'}\n\n```{.r .cell-code  code-line-numbers=\"4-9\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n      .default = ethnic\n    )\n  )\n\ndf_clean |> \n  count(ethnic_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 2\n  ethnic_clean     n\n  <chr>        <int>\n1 hispanic         5\n2 not hispanic    25\n```\n:::\n:::\n\n### Confirm\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-37_d80b4a28d83382d334a5b37e3dcf2b3f'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(ethnic_clean, ethnic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã— 3\n  ethnic_clean ethnic           n\n  <chr>        <chr>        <int>\n1 hispanic     Hispanic         1\n2 hispanic     hispamnic        1\n3 hispanic     hispanic         3\n4 not hispanic NOT hispanic     1\n5 not hispanic not hispanic    24\n```\n:::\n:::\n:::\n\n## Exercise\n\n<br>\n\nComplete Data Cleaning Fundamentals Exercise SP1.\n\n<br>\n\n[--\\> Take me to the exercises \\<--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#sp1){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_f93829a2\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:4em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Replace values with missing\n\n::: panel-tabset\n### Problem\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-39_5ec4799833346223e8c421dcaa328555'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(end_na) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 2\n   end_na     n\n    <dbl> <int>\n 1   -99      1\n 2   133.     1\n 3   135.     1\n 4   135.     1\n 5   136.     1\n 6   137.     1\n 7   137.     1\n 8   138.     1\n 9   138.     1\n10   138.     1\n# â„¹ 20 more rows\n```\n:::\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-40_a8b1835af77196fa89f394f0d7c2a2e0'}\n\n```{.r .cell-code}\ndf_clean |> \n  ggplot(aes(x = end_na)) +\n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-40-1.png){width=960}\n:::\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-41_c14fbfcebb530273ce7c8efe4659085a'}\n\n```{.r .cell-code  code-line-numbers=\"9\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99)\n  ) \n```\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-42_927aad43b3a8f97340b2b226e0a7aa76'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(end_na, end_na_clean) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 3\n   end_na end_na_clean     n\n    <dbl>        <dbl> <int>\n 1   -99           NA      1\n 2   133.         133.     1\n 3   135.         135.     1\n 4   135.         135.     1\n 5   136.         136.     1\n 6   137.         137.     1\n 7   137.         137.     1\n 8   138.         138.     1\n 9   138.         138.     1\n10   138.         138.     1\n# â„¹ 20 more rows\n```\n:::\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-43_5821cccdc4f9dbac8d0d0819d008f318'}\n\n```{.r .cell-code}\ndf_clean |> \n  ggplot(aes(x = end_na_clean)) +\n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-43-1.png){width=960}\n:::\n:::\n:::\n:::\n:::\n\n## Incorrect variable type\n\n::: panel-tabset\n### Problem\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-44_09583c812add75b2273eae9dca6e57c5'}\n\n```{.r .cell-code}\ndf_raw |> \n  select(end_emo) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 31\nColumns: 1\n$ end_emo <chr> \"31.980531232702354\", \"43.154961592472482\", \"36.88112394645107â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-45_b4b515166db9e0d7e7b7e21c7a324e56'}\n\n```{.r .cell-code}\nmean(df_raw[[\"end_emo\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in mean.default(df_raw[[\"end_emo\"]], na.rm = TRUE): argument is not\nnumeric or logical: returning NA\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-46_4f2a27bf935c47a8ac60d880c817c202'}\n\n```{.r .cell-code}\ndf_raw[[\"end_emo\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"31.980531232702354\" \"43.154961592472482\" \"36.881123946451076\"\n [4] \"58.670309483569042\" \"58.863864661125419\" \"34.593046073414015\"\n [7] \"63.285059520403976\" \"65.313599031979081\" \"27.976656095216335\"\n[10] \"46.802992507671597\" \"33.122563864954309\" \"49.240520034972612\"\n[13] \"47.050604139781761\" \"54.487640962873577\" \"not done\"          \n[16] NA                   \"49.084529664712441\" \"27.370965295845295\"\n[19] \"60.432712720552317\" \"26.162987564588903\" \"48.329539382030802\"\n[22] \"40.735196376550661\" \"27.000188739872502\" \"57.019771433515629\"\n[25] \"39.783229029414606\" \"52.110256961065794\" \"37.098188331548307\"\n[28] \"39.264033750725694\" \"70.34798440037369\"  \"29.839211956263874\"\n[31] \"42.853436653960713\"\n```\n:::\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-47_15fd71b273c51ae47748be8007637740'}\n\n```{.r .cell-code  code-line-numbers=\"10\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric()\n  ) \n```\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-48_d43be16856dd9b5c31da6ba482b7479b'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(end_emo, end_emo_clean) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 2\n$ end_emo       <chr> \"31.980531232702354\", \"43.154961592472482\", \"36.88112394â€¦\n$ end_emo_clean <dbl> 31.98053, 43.15496, 36.88112, 58.67031, 58.86386, 34.593â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-49_95dfd0cfe73b294c47405445541d4f0f'}\n\n```{.r .cell-code}\nmean(df_clean[[\"end_emo_clean\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 44.78813\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-50_7ce910cd3ba8b38cce38dd7bad5f3571'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(end_emo_clean, end_emo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 3\n   end_emo_clean end_emo                n\n           <dbl> <chr>              <int>\n 1          26.2 26.162987564588903     1\n 2          27.0 27.000188739872502     1\n 3          27.4 27.370965295845295     1\n 4          28.0 27.976656095216335     1\n 5          29.8 29.839211956263874     1\n 6          32.0 31.980531232702354     1\n 7          33.1 33.122563864954309     1\n 8          34.6 34.593046073414015     1\n 9          36.9 36.881123946451076     1\n10          37.1 37.098188331548307     1\n# â„¹ 20 more rows\n```\n:::\n:::\n:::\n:::\n:::\n\n## Correcting dates\n\n::: panel-tabset\n### Problem\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-51_0a26e6fc3a85fe09bb2381bef52df887'}\n\n```{.r .cell-code}\ndf_raw |> \n  select(start_date) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 31\nColumns: 1\n$ start_date <dbl> 44208, 44215, 44230, 44245, 44255, 44259, 44264, 44999, 442â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-52_354628d7840c95dd05cccc9b8fd2e6e4'}\n\n```{.r .cell-code}\ndf_raw[[\"start_date\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 44208 44215 44230 44245 44255 44259 44264 44999 44276 44278 44297 44308\n[13] 44313 44318 44324    NA 44329 44332 44346 44358 44370 44383 44391 44397\n[25] 44412 44425 44434 44444 44461 44475 44500\n```\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-53_101e48483c35132642f9b20e508aacf1'}\n\n```{.r .cell-code  code-line-numbers=\"11\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric(),\n    start_date_clean = janitor::convert_to_date(start_date)\n  ) \n```\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-54_e2d5c0cefe8e804ab84199b44baeafe5'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(start_date, start_date_clean) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 2\n$ start_date       <dbl> 44208, 44215, 44230, 44245, 44255, 44259, 44264, 4499â€¦\n$ start_date_clean <date> 2021-01-12, 2021-01-19, 2021-02-03, 2021-02-18, 2021â€¦\n```\n:::\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-55_9b80f23c688856d29a05d920d9a2e265'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(start_date, start_date_clean) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 3\n   start_date start_date_clean     n\n        <dbl> <date>           <int>\n 1      44208 2021-01-12           1\n 2      44215 2021-01-19           1\n 3      44230 2021-02-03           1\n 4      44245 2021-02-18           1\n 5      44255 2021-02-28           1\n 6      44259 2021-03-04           1\n 7      44264 2021-03-09           1\n 8      44276 2021-03-21           1\n 9      44278 2021-03-23           1\n10      44297 2021-04-11           1\n# â„¹ 20 more rows\n```\n:::\n:::\n:::\n:::\n:::\n\n## Extracting numbers from text\n\n::: panel-tabset\n### Problem\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-56_e1e8a0488741bb02c743be24ac8fd9a2'}\n\n```{.r .cell-code}\ndf_raw |> \n  select(start_na) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 31\nColumns: 1\n$ start_na <chr> \"137mmol/L\", \"142mmol/L\", \"140mmol/L\", \"139mmol/L\", \"144mmol/â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-57_787670ed4aa97171f77a91a05935082d'}\n\n```{.r .cell-code}\nmean(df_raw[[\"start_na\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in mean.default(df_raw[[\"start_na\"]], na.rm = TRUE): argument is not\nnumeric or logical: returning NA\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-58_10a0ace0478c204fea6e283ad0e1ca21'}\n\n```{.r .cell-code}\ndf_raw[[\"start_na\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"137mmol/L\" \"142mmol/L\" \"140mmol/L\" \"139mmol/L\" \"144mmol/L\" \"145mmol/L\"\n [7] \"142mmol/L\" \"138mmol/L\" \"140mmol/L\" \"137mmol/L\" \"143mmol/L\" \"136mmol/L\"\n[13] \"135mmol/L\" \"141mmol/L\" \"133mmol/L\" NA          \"135mmol/L\" \"143mmol/L\"\n[19] \"136mmol/L\" \"144mmol/L\" \"145mmol/L\" \"140mmol/L\" \"141mmol/L\" \"142mmol/L\"\n[25] \"138mmol/L\" \"139mmol/L\" \"142mmol/L\" \"144mmol/L\" \"139mmol/L\" \"138mmol/L\"\n[31] \"140mmol/L\"\n```\n:::\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-59_b7b522bdaa78bff6e37c33620d077b34'}\n\n```{.r .cell-code  code-line-numbers=\"11\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric(),\n    start_na_clean = parse_number(start_na)\n  ) \n```\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-60_1e687c008f40b3625136e87ff396068c'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(start_na, start_na_clean) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 2\n$ start_na       <chr> \"137mmol/L\", \"142mmol/L\", \"140mmol/L\", \"139mmol/L\", \"14â€¦\n$ start_na_clean <dbl> 137, 142, 140, 139, 144, 145, 142, 138, 140, 137, 143, â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-61_1b70105fd5d1deb9fccf9dc923577b94'}\n\n```{.r .cell-code}\nmean(df_clean[[\"start_na_clean\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 139.9333\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-62_c355aca12ea3130284b0eb409a2b7cde'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(start_na_clean, start_na)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 Ã— 3\n   start_na_clean start_na      n\n            <dbl> <chr>     <int>\n 1            133 133mmol/L     1\n 2            135 135mmol/L     2\n 3            136 136mmol/L     2\n 4            137 137mmol/L     2\n 5            138 138mmol/L     3\n 6            139 139mmol/L     3\n 7            140 140mmol/L     4\n 8            141 141mmol/L     2\n 9            142 142mmol/L     4\n10            143 143mmol/L     2\n11            144 144mmol/L     3\n12            145 145mmol/L     2\n```\n:::\n:::\n:::\n:::\n:::\n\n## Exercise\n\n<br>\n\nComplete Data Cleaning Fundamentals Exercise SP2.\n\n<br>\n\n[--\\> Take me to the exercises \\<--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#sp2){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_848070b6\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:4em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Character variable should be a factor\n\n::: panel-tabset\n### Problem\n\n::: columns\n::: {.column width=\"35%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-64_bb3bdd257d56369f038288007698b2cd'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 Ã— 2\n  treatment     n\n  <chr>     <int>\n1 oza          10\n2 upa          10\n3 uste         10\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-65_cd0528ede3b2b2e91e6253d2e7e75657'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(ethnic_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 2\n  ethnic_clean     n\n  <chr>        <int>\n1 hispanic         5\n2 not hispanic    25\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"65%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-66_1b7460c9b837bd59ddda8eb265db8bad'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(treatment, ethnic_clean) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 2\n$ treatment    <chr> \"upa\", \"uste\", \"oza\", \"upa\", \"oza\", \"uste\", \"uste\", \"oza\"â€¦\n$ ethnic_clean <chr> \"hispanic\", \"not hispanic\", \"not hispanic\", \"not hispanicâ€¦\n```\n:::\n:::\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-67_9ef4e15072eecef0aa11df9b41489574'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(treatment, ethnic_clean) |> \n  gtsummary::tbl_summary(by = treatment)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"xnypocpqbx\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#xnypocpqbx table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#xnypocpqbx thead, #xnypocpqbx tbody, #xnypocpqbx tfoot, #xnypocpqbx tr, #xnypocpqbx td, #xnypocpqbx th {\n  border-style: none;\n}\n\n#xnypocpqbx p {\n  margin: 0;\n  padding: 0;\n}\n\n#xnypocpqbx .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#xnypocpqbx .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#xnypocpqbx .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#xnypocpqbx .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#xnypocpqbx .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#xnypocpqbx .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#xnypocpqbx .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#xnypocpqbx .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#xnypocpqbx .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#xnypocpqbx .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#xnypocpqbx .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#xnypocpqbx .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#xnypocpqbx .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#xnypocpqbx .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#xnypocpqbx .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xnypocpqbx .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#xnypocpqbx .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#xnypocpqbx .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#xnypocpqbx .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xnypocpqbx .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#xnypocpqbx .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xnypocpqbx .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#xnypocpqbx .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xnypocpqbx .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xnypocpqbx .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xnypocpqbx .gt_left {\n  text-align: left;\n}\n\n#xnypocpqbx .gt_center {\n  text-align: center;\n}\n\n#xnypocpqbx .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#xnypocpqbx .gt_font_normal {\n  font-weight: normal;\n}\n\n#xnypocpqbx .gt_font_bold {\n  font-weight: bold;\n}\n\n#xnypocpqbx .gt_font_italic {\n  font-style: italic;\n}\n\n#xnypocpqbx .gt_super {\n  font-size: 65%;\n}\n\n#xnypocpqbx .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#xnypocpqbx .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#xnypocpqbx .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#xnypocpqbx .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#xnypocpqbx .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#xnypocpqbx .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#xnypocpqbx .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;Characteristic&lt;/strong&gt;\"><strong>Characteristic</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;oza&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>oza</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;upa&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>upa</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;uste&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>uste</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">ethnic_clean</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\"></td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\"></td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\"></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â hispanic</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">4 (40%)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">1 (10%)</td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\">0 (0%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â not hispanic</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">6 (60%)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">9 (90%)</td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\">10 (100%)</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"4\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span> n (%)</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n:::\n:::\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-68_8da864af2cc1e8ea3c26d2700403d1f3'}\n\n```{.r .cell-code  code-line-numbers=\"8,12\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |> fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n  ) \n```\n:::\n\n<br>\n\nSee the [forcats package](https://forcats.tidyverse.org/) for other factor handling solutions.\n\n### Confirm\n\n::: columns\n::: {.column width=\"35%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-69_b31409f18bae0d18a46421f52edbcf24'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 Ã— 2\n  treatment     n\n  <fct>     <int>\n1 upa          10\n2 uste         10\n3 oza          10\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-70_8f1959a699aa730f18c14aea7ad0a81b'}\n\n```{.r .cell-code}\ndf_clean |> \n  count(ethnic_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 Ã— 2\n  ethnic_clean     n\n  <fct>        <int>\n1 not hispanic    25\n2 hispanic         5\n```\n:::\n:::\n:::\n:::\n\n::: {.column .fragment width=\"65%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-71_236678f72c3638256b515c1486f3f0ca'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(treatment, ethnic_clean) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 2\n$ treatment    <fct> upa, uste, oza, upa, oza, uste, uste, oza, upa, oza, upa,â€¦\n$ ethnic_clean <fct> hispanic, not hispanic, not hispanic, not hispanic, not hâ€¦\n```\n:::\n:::\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-72_80f733d8efb693a5b20f90407eb11775'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(treatment, ethnic_clean) |> \n  gtsummary::tbl_summary(by = treatment)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"yzjuixmtlj\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#yzjuixmtlj table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#yzjuixmtlj thead, #yzjuixmtlj tbody, #yzjuixmtlj tfoot, #yzjuixmtlj tr, #yzjuixmtlj td, #yzjuixmtlj th {\n  border-style: none;\n}\n\n#yzjuixmtlj p {\n  margin: 0;\n  padding: 0;\n}\n\n#yzjuixmtlj .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#yzjuixmtlj .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#yzjuixmtlj .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#yzjuixmtlj .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#yzjuixmtlj .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#yzjuixmtlj .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#yzjuixmtlj .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#yzjuixmtlj .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#yzjuixmtlj .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#yzjuixmtlj .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#yzjuixmtlj .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#yzjuixmtlj .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#yzjuixmtlj .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#yzjuixmtlj .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#yzjuixmtlj .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yzjuixmtlj .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#yzjuixmtlj .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#yzjuixmtlj .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#yzjuixmtlj .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yzjuixmtlj .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#yzjuixmtlj .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yzjuixmtlj .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#yzjuixmtlj .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yzjuixmtlj .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#yzjuixmtlj .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#yzjuixmtlj .gt_left {\n  text-align: left;\n}\n\n#yzjuixmtlj .gt_center {\n  text-align: center;\n}\n\n#yzjuixmtlj .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#yzjuixmtlj .gt_font_normal {\n  font-weight: normal;\n}\n\n#yzjuixmtlj .gt_font_bold {\n  font-weight: bold;\n}\n\n#yzjuixmtlj .gt_font_italic {\n  font-style: italic;\n}\n\n#yzjuixmtlj .gt_super {\n  font-size: 65%;\n}\n\n#yzjuixmtlj .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#yzjuixmtlj .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#yzjuixmtlj .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#yzjuixmtlj .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#yzjuixmtlj .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#yzjuixmtlj .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#yzjuixmtlj .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;Characteristic&lt;/strong&gt;\"><strong>Characteristic</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;upa&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>upa</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;uste&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>uste</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;oza&lt;/strong&gt;, N = 10&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>oza</strong>, N = 10<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">ethnic_clean</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\"></td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\"></td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\"></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â not hispanic</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">9 (90%)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">10 (100%)</td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\">6 (60%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â hispanic</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">1 (10%)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">0 (0%)</td>\n<td headers=\"stat_3\" class=\"gt_row gt_center\">4 (40%)</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"4\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span> n (%)</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n:::\n:::\n:::\n:::\n:::\n:::\n\n## Exercise\n\n<br>\n\nComplete Data Cleaning Fundamentals Exercise SP3.\n\n<br>\n\n[--\\> Take me to the exercises \\<--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#sp3){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_30defdd8\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:4em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Separating values\n\n::: panel-tabset\n### Problem\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-74_30ba3d598ec230cae18962c82daf5341'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(start_bp) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 1\n$ start_bp <chr> \"114/72\", \"132/86\", \"124/92\", \"144/83\", \"122/78\", \"121/80\", \"â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-75_8b47888465512454f30d2975d91f871b'}\n\n```{.r .cell-code}\nmean(df_clean[[\"start_bp\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-76_30fb4a80f32854875c87914a79b36f03'}\n\n```{.r .cell-code}\ndf_clean[[\"start_bp\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"114/72\" \"132/86\" \"124/92\" \"144/83\" \"122/78\" \"121/80\" \"133/74\" \"116/73\"\n [9] \"118/66\" \"122/78\" \"126/82\" \"114/68\" \"118/73\" \"106/59\" \"112/69\" \"114/76\"\n[17] \"124/80\" \"120/68\" \"119/77\" \"116/74\" \"121/80\" \"112/58\" \"117/67\" \"118/73\"\n[25] \"116/74\" \"126/84\" \"144/96\" \"120/84\" \"115/75\" \"142/92\"\n```\n:::\n:::\n:::\n\n### Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-77_9c2fdac371cd7d44cac265f09e8c6ca8'}\n\n```{.r .cell-code  code-line-numbers=\"14,15\"}\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |> fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n    ) |>  \n  separate_wider_delim(start_bp, delim =\"/\", names = c(\"bp_systolic\", \"bp_diastolic\"), cols_remove = FALSE) |> \n  mutate(across(c(bp_systolic, bp_diastolic), as.numeric)) \n```\n:::\n\n### Confirm\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-78_1571eacce20289328d51baca7474ab6f'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(start_bp, bp_systolic, bp_diastolic) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 3\n$ start_bp     <chr> \"114/72\", \"132/86\", \"124/92\", \"144/83\", \"122/78\", \"121/80â€¦\n$ bp_systolic  <dbl> 114, 132, 124, 144, 122, 121, 133, 116, 118, 122, 126, 11â€¦\n$ bp_diastolic <dbl> 72, 86, 92, 83, 78, 80, 74, 73, 66, 78, 82, 68, 73, 59, 6â€¦\n```\n:::\n:::\n\n<br>\n\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-79_aab6efb556a61600df25905f466947f6'}\n\n```{.r .cell-code}\nmean(df_clean[[\"bp_systolic\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 121.5333\n```\n:::\n\n```{.r .cell-code}\nmean(df_clean[[\"bp_diastolic\"]], na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 76.36667\n```\n:::\n:::\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: fragment\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-80_af8a437ada97702ea5e38c0b4378799e'}\n\n```{.r .cell-code}\ndf_clean[[\"bp_systolic\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 114 132 124 144 122 121 133 116 118 122 126 114 118 106 112 114 124 120 119\n[20] 116 121 112 117 118 116 126 144 120 115 142\n```\n:::\n\n```{.r .cell-code}\ndf_clean[[\"bp_diastolic\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 72 86 92 83 78 80 74 73 66 78 82 68 73 59 69 76 80 68 77 74 80 58 67 73 74\n[26] 84 96 84 75 92\n```\n:::\n:::\n:::\n:::\n:::\n:::\n\n## Assigning labels\n\n::: panel-tabset\n### Problem\n\nWhat does anything mean?\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-81_6d26af5b1153b526c104e588dddef054'}\n\n```{.r .cell-code}\ndf_clean |> \n  select(pat_id, start_na, start_na_clean, pre_post_wt_kg, start_emo) |> \n  view()\n```\n:::\n\n![](images/df_nolabels.PNG)\n\n### Solution 1\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-82_d5ef80ef0a2e6c65a0447d72148d8b9b'}\n\n```{.r .cell-code}\n# first import data dictionary\ndf_dictionary <- read_excel(\n  path = here(\"data\", \"messy_uc.xlsx\"),\n  sheet = \"Data_Dictionary\"\n)\ndf_dictionary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 33 Ã— 5\n   Variable       Details                                      Units Range ...5 \n   <chr>          <chr>                                        <chr> <chr> <chr>\n 1 pat_id         Patient Identifier                           digiâ€¦ 001-â€¦ <NA> \n 2 treatment      Treatment for UC                             <NA>  upadâ€¦ <NA> \n 3 start_date     Date of start of treatment                   digiâ€¦ YYYYâ€¦ <NA> \n 4 ethnic         Ethnicity - hispanic or not hispanic         <NA>  hispâ€¦ <NA> \n 5 race           Race - one of 7 choices                      <NA>  caucâ€¦ <NA> \n 6 dob            date of birth                                digiâ€¦ YYYYâ€¦ <NA> \n 7 start_bp       blood pressure at start - systolic/diastolic mm Hg systâ€¦ <NA> \n 8 pre/post_wt_kg weight in kilograms at start/end             kiloâ€¦ 48-1â€¦ <NA> \n 9 start_mes      Mayo endoscopic Score at start of treatment  poinâ€¦ 0-3   <NA> \n10 start_bss      Bowel symptom score at start                 poinâ€¦ 0-100 QOL â€¦\n# â„¹ 23 more rows\n```\n:::\n:::\n\n### Solution 2\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-83_5ba4371658b97558bfdc12c79be441ff'}\n\n```{.r .cell-code}\n# second create a named vector of variable names and variable labels\nvec_variables <- df_dictionary |> \n  select(Variable, Details) |> \n  deframe()\n\nvec_variables\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                        pat_id \n                          \"Patient Identifier\" \n                                     treatment \n                            \"Treatment for UC\" \n                                    start_date \n                  \"Date of start of treatment\" \n                                        ethnic \n        \"Ethnicity - hispanic or not hispanic\" \n                                          race \n                     \"Race - one of 7 choices\" \n                                           dob \n                               \"date of birth\" \n                                      start_bp \n\"blood pressure at start - systolic/diastolic\" \n                                pre/post_wt_kg \n            \"weight in kilograms at start/end\" \n                                     start_mes \n \"Mayo endoscopic Score at start of treatment\" \n                                     start_bss \n                \"Bowel symptom score at start\" \n                                     start_abd \n            \"Abdominal symptom score at start\" \n                                     start_sys \n             \"Systemic symptom score at start\" \n                                  start_coping \n                       \"Coping score at start\" \n                                     start_emo \n            \"Emotional symptom score at start\" \n                                      start_dl \n       \"Impact on Daily living score at start\" \n                                     start_wbc \n    \"White blood cell count in blood at start\" \n                                     start_plt \n            \"Platelet count in blood at start\" \n                                      start_na \n              \"Sodium level in serum at start\" \n                                       start_k \n           \"Potassium level in serum at start\" \n                                     end_month \n                          \"Month of end visit\" \n                                       end_day \n                            \"Day of end visit\" \n                                      end_year \n                           \"Year of end visit\" \n                                       end_mes \n   \"Mayo endoscopic Score at end of treatment\" \n                                       end_bss \n                  \"Bowel symptom score at end\" \n                                       end_abd \n              \"Abdominal symptom score at end\" \n                                       end_sys \n               \"Systemic symptom score at end\" \n                                    end_coping \n                         \"Coping score at end\" \n                                       end_emo \n              \"Emotional symptom score at end\" \n                                        end_dl \n         \"Impact on Daily living score at end\" \n                                       end_wbc \n      \"White blood cell count in blood at end\" \n                                       end_plt \n              \"Platelet count in blood at end\" \n                                        end_na \n                \"Sodium level in serum at end\" \n                                         end_k \n             \"Potassium level in serum at end\" \n```\n:::\n:::\n\n### Solution 3\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-84_fd5e7b3df42a168a22cee3e6d3f2b2ab'}\n\n```{.r .cell-code  code-line-numbers=\"17,18|19,20,21,22,23,24,25,26\"}\n# assign labels to the data set\ndf_clean <- df_raw |>\n  janitor::clean_names() |> \n  janitor::remove_empty(which = c(\"rows\", \"cols\")) |> \n  mutate(\n    ethnic_clean = case_when(\n      ethnic %in%  c(\"hispanic\", \"Hispanic\", \"hispamnic\") ~ \"hispanic\",\n      ethnic %in%  c(\"NOT hispanic\", \"not hispanic\") ~ \"not hispanic\",\n    ) |> fct_infreq(),\n    end_na_clean = na_if(end_na, -99),\n    end_emo_clean = na_if(end_emo, \"not done\") |> as.numeric(),\n    start_na_clean = parse_number(start_na),\n    treatment = fct_relevel(treatment, \"upa\", \"uste\", \"oza\")\n    ) |>  \n  separate_wider_delim(start_bp, delim =\"/\", names = c(\"bp_systolic\", \"bp_diastolic\"), cols_remove = FALSE) |> \n  mutate(across(c(bp_systolic, bp_diastolic), as.numeric)) |> \n  # assign labels to all variables from the codebook\n  labelled::set_variable_labels(!!!vec_variables, .strict = FALSE) |> \n  # assign labels to new derived variables that did not exist in the code book\n  labelled::set_variable_labels(\n    ethnic_clean = \"Ethnicity\",\n    start_na_clean = \"Sodium level in serum at start\",\n    end_na_clean = \"Sodium level in serum at end\",\n    end_emo_clean = \"Emotional symptom score at end\",\n    bp_systolic = \"Systolic blood pressure\",\n    bp_diastolic = \"Diastolic blood pressure\"\n  )\n```\n:::\n\n### Confirm 1\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-85_e9b25a5986997f1c076d5a2215f86b52'}\n\n```{.r .cell-code}\n# view entire data set\ndf_clean |> \n  select(pat_id, start_na, start_na_clean, pre_post_wt_kg, start_emo) |> \n  view()\n```\n:::\n\n![](images/df_yeslabels.PNG)\n\n<br>\n\nðŸ¤” Why doesn't `pre_post_wt_kg` have a label?\n\n\n### Confirm 2\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-86_2f0febc44bbb3f43d59314a2b4b66f83'}\n\n```{.r .cell-code}\n# view structure of data frame\ndf_clean |>\n   select(pat_id, start_na, start_na_clean, pre_post_wt_kg, start_emo) |> \n   str()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [30 Ã— 5] (S3: tbl_df/tbl/data.frame)\n $ pat_id        : chr [1:30] \"001\" \"002\" \"003\" \"004\" ...\n  ..- attr(*, \"label\")= chr \"Patient Identifier\"\n $ start_na      : chr [1:30] \"137mmol/L\" \"142mmol/L\" \"140mmol/L\" \"139mmol/L\" ...\n  ..- attr(*, \"label\")= chr \"Sodium level in serum at start\"\n $ start_na_clean: num [1:30] 137 142 140 139 144 145 142 138 140 137 ...\n  ..- attr(*, \"label\")= chr \"Sodium level in serum at start\"\n $ pre_post_wt_kg: chr [1:30] \"84/82\" \"77/77\" \"74/75\" \"66/65\" ...\n $ start_emo     : num [1:30] 73.3 55.7 36.6 80.8 72.5 ...\n  ..- attr(*, \"label\")= chr \"Emotional symptom score at start\"\n```\n:::\n:::\n:::\n\n\n\n# Stage 2 <br>Wrangling your Data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-87_049db145ec1b9d70258eb1cc9bf2901c'}\n\n:::\n\n## Where are We Now?\n\n- We have done DEV (Data Exploration and Validation) - with more validation to be done. Data validation is a continuous process, right up to Data Lock.\n- We discussed the importance of preventing data errors at the source - data collection and entry (preferably using a tool with data validation at entry - like REDCap)\n- We did Stage 1 cleaning - clean variable names, remove empty columns/rows, fix variable types/classes (characters in numeric, recoding factors, date madness), address missingness, violations of tidy data principles (separate), added meaningful variable labels.\n- While Stage 1 is required in nearly all projects, Stage 2 data cleaning is frequently needed, but not in all projects.\n\n## Stage 2 Data Cleaning\n\n- We will cover these frequent but optional topics:\n  - Restructuring data as Long or Wide format\n  - Thickening or padding Longitudinal Data\n  - Joining multiple datasets\n\n## Restructuring data to Long or Wide format\n\n\nWide Format - One Row per Patient\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-88_53115107a189dd3ff400072e7bc8f789'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 8\n  pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n  <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n1 001    upa               3       0      75.9    9.85      79.3    39.8\n2 002    uste              2       1      54.7   32.7       58.6    49.4\n3 003    oza               1       1      28.5   28.5       32.2    35.9\n4 004    upa               3       1      77.2   33.2       75.6    50.2\n5 005    oza               3       2      78.8   56.8       74.3    65.0\n6 006    uste              2       1      54.4   32.4       45.3    36.0\n```\n:::\n:::\n\nLong Format - One Row per Measurement\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-89_d34a7ef01b3864a442b7164193aa82a9'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 4\n  pat_id treatment measure   score\n  <chr>  <chr>     <chr>     <dbl>\n1 001    upa       start_mes  3   \n2 001    upa       end_mes    0   \n3 001    upa       start_bss 75.9 \n4 001    upa       end_bss    9.85\n5 001    upa       start_emo 79.3 \n6 001    upa       end_emo   39.8 \n7 002    uste      start_mes  2   \n8 002    uste      end_mes    1   \n9 002    uste      start_bss 54.7 \n```\n:::\n:::\n\n\n\n## The Unit of Analysis - Wide by Patient\n\n- We may want to do an analysis by patient, as each patient may (or may not) have the outcome. If we have multiple observations, or data points on each patient, this leads to wide data, with one row per patient.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-90_e32c07779fb19435442dc609b08e49fc'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 8\n  pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n  <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n1 001    upa               3       0      75.9    9.85      79.3    39.8\n2 002    uste              2       1      54.7   32.7       58.6    49.4\n3 003    oza               1       1      28.5   28.5       32.2    35.9\n4 004    upa               3       1      77.2   33.2       75.6    50.2\n5 005    oza               3       2      78.8   56.8       74.3    65.0\n6 006    uste              2       1      54.4   32.4       45.3    36.0\n```\n:::\n:::\n\n\n\n## The Unit of Analysis - Long by Visit\n\n- We are often interested in the change in an outcome over time.\n- To make this work, we need one row per measurement of the outcome. This leads to long data, with multiple visits and measurements for each patient.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-91_dacdb891920d570f6bc5ae9a260fb109'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n\n## Deciding on the Unit of Analysis\n\n-   This Unit of Analysis usually depends on the `Question` we ask\n\nIs the Unit of Analysis the Patient?\n\n-   Did the patient die?\n-   Did the patient have the outcome of colectomy?\n-   Did the patient reach disease remission?\n\nIs the Unit of Analysis the Visit/Encounter?\n\n-   Often these are within-patient outcomes\n    -   Did the C-reactive protein improve from Week 0 to Week 8?\n    -   Did the sickle cell crises/year decrease after CRISPR gene Rx?\n    -   Did the endoscopic score decrease on treatment vs placebo?\n\n## Deciding on the Unit of Analysis\n\n- You will most often use long data, and this data structure allows you to look at multiple predictors and outcomes, like blood pressure, a PHQ-9 depression questionnaire, and a hemoglobin measurement.\n- Depending on the analysis question, you may want to use wide data, and analyze by patient (usually with dichotomous outcomes).\n\n## Deciding on the Unit of Analysis\n- For inpatient data, you may have multiple measurements in the same visit or day, so we need to decide _a priori_ on how to handle multiple observations of the same type (e.g., vitals q6h) in the same day.\n    -   use the `0600` observation each day?\n    -   use the daily average for SBP and DBP?\n    -   use the max values each day?\n- Sometimes, you may want to do analysis on both long and wide data in the same project. \n- It is often helpful to be able to pivot your data between long and wide structures.\n\n\n## Reshaping your data with tidyr\n\n::: panel-tabset\n### The Problem\n\n-   We often *enter* data by patient\n-   Spreadsheets encourage us to enter longitudinal data as long rows (per patient)\n-   We end up with `wide`, rather than `tall` data\n\n### Wide Version of Data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-92_79282072215cabaf88c317c8f33c608c'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 8\n  pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n  <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n1 001    upa               3       0      75.9    9.85      79.3    39.8\n2 002    uste              2       1      54.7   32.7       58.6    49.4\n3 003    oza               1       1      28.5   28.5       32.2    35.9\n4 004    upa               3       1      77.2   33.2       75.6    50.2\n5 005    oza               3       2      78.8   56.8       74.3    65.0\n6 006    uste              2       1      54.4   32.4       45.3    36.0\n```\n:::\n:::\n\n### Tall Version of Data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-93_be6ef4f794946a632e50504f3b8ace6d'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n:::\n\n## Reshaping your data with tidyr\n\n-   R (and most R functions) are vectorized to handle tall data\n-   One small observation per row\n-   Most analyses in R are easier with tall data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-94_6109470b4473781e215e2d6d44e27e7f'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n## Pivoting Longer (common)\n\n-   We need to 'pivot' data from wide to tall on the regular\n-   This \"lengthens\" data, increasing the number of rows, and decreasing the number of columns\n-   We will be looking at Visit Dates (Start vs End) and Measures\n\n## Pivoting Longer\n\n-   Arguments: `data`, `cols`, `names_to`, `values_to`, and many optional arguments\n-   Details from the tidyverse help page are [here](https://tidyr.tidyverse.org/reference/pivot_longer.html)\n-   `data` = your dataframe/tibble - you can pipe this in\n-   `cols` = columns to pivot, as a vector of names, or by number, or selected with [tidyselect](https://tidyselect.r-lib.org) functions\n-   `names_to` = A character vector specifying the new column or columns to create from the information stored in the column names of data specified by cols.\n-   `values_to` = A string specifying the name of the column to create from the data stored in cell values.\n\n## Pivoting Longer (Example)\n\nLet's start with the wide version (selected columns from messy_uc)\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-95_e9ed64a4d6dfd4857e78ee19ef73fcb8'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n 1 001    upa               3       0      75.9    9.85      79.3    39.8\n 2 002    uste              2       1      54.7   32.7       58.6    49.4\n 3 003    oza               1       1      28.5   28.5       32.2    35.9\n 4 004    upa               3       1      77.2   33.2       75.6    50.2\n 5 005    oza               3       2      78.8   56.8       74.3    65.0\n 6 006    uste              2       1      54.4   32.4       45.3    36.0\n 7 007    uste              3       2      79.7   57.7       66.6    57.8\n 8 008    oza               3       2      75.0   53.0       74.5    62.0\n 9 009    upa               2       0      53.1    9.06      50.0    27.8\n10 010    oza               3       1      78.9   34.9       72.5    45.9\n# â„¹ 20 more rows\n```\n:::\n:::\n\n-   Note that there are 30 rows, one per patient, with 6 measured quantities for each patient.\n\n## Pivoting Longer (Example)\n\nThis is the tall version we want to end up with.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-96_9df4d1892032fec8734e548096afdc27'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n-   Note that there now 180 rows (30\\*6), with one row per observation measure.\n\n## Doing the pivot_longer()\n\nWhat values do we want for these key arguments in order to pivot_longer?\n\n-   `cols` (which columns to pivot?)\n-   `names_to` (variable to store the names)\n-   `values_to` (variable to store the values)\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-97_f5ff7bdab61b3355634f6614822e5eb3'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n 1 001    upa               3       0      75.9    9.85      79.3    39.8\n 2 002    uste              2       1      54.7   32.7       58.6    49.4\n 3 003    oza               1       1      28.5   28.5       32.2    35.9\n 4 004    upa               3       1      77.2   33.2       75.6    50.2\n 5 005    oza               3       2      78.8   56.8       74.3    65.0\n 6 006    uste              2       1      54.4   32.4       45.3    36.0\n 7 007    uste              3       2      79.7   57.7       66.6    57.8\n 8 008    oza               3       2      75.0   53.0       74.5    62.0\n 9 009    upa               2       0      53.1    9.06      50.0    27.8\n10 010    oza               3       1      78.9   34.9       72.5    45.9\n# â„¹ 20 more rows\n```\n:::\n:::\n\n## Pivoting Longer In Action\n\n::: panel-tabset\n\n### Problem: Wide\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-98_361e559b81b711a3b091aa7cfda128eb'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n 1 001    upa               3       0      75.9    9.85      79.3    39.8\n 2 002    uste              2       1      54.7   32.7       58.6    49.4\n 3 003    oza               1       1      28.5   28.5       32.2    35.9\n 4 004    upa               3       1      77.2   33.2       75.6    50.2\n 5 005    oza               3       2      78.8   56.8       74.3    65.0\n 6 006    uste              2       1      54.4   32.4       45.3    36.0\n 7 007    uste              3       2      79.7   57.7       66.6    57.8\n 8 008    oza               3       2      75.0   53.0       74.5    62.0\n 9 009    upa               2       0      53.1    9.06      50.0    27.8\n10 010    oza               3       1      78.9   34.9       72.5    45.9\n# â„¹ 20 more rows\n```\n:::\n:::\n\n### Code: pivot_longer\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-99_0d6514284d82dc06fb628e140f64158b'}\n\n```{.r .cell-code}\nwide |> # <1>\n  pivot_longer(\n    cols = \"start_mes\":\"end_emo\", \n               names_to = \"measure\", # <2>\n               values_to = \"score\" # <3>\n    ) # <4>\n```\n:::\n1. start with wide data, and pivot_longer\n2. Which columns to pivot (names in quotes), could also use 3:8\n3. which column (quotes) the pivoted variable names should go into\n4. which column (quotes) the pivoted values should go into\n\n### Result: Tall\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-100_f82019c9d52632205ccf9a27cf9ec365'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n-   Does this make sense so far?\n-   Zoom reaction: \"thumbs up\" emoji ðŸ‘ if yes\n    -   \"raised hand\" emoji âœ‹ if puzzled/questions \n    \n:::\n\n## One Minor Issue - Separation of measure\n\n::: panel-tabset\n\n### Problem\n\n-   the \"measure\" column combines a timepoint and the measure\n-   Needs to be separated.\n-   You already know how to use *separate()*\n-   Arguments\n    -   `col`\n    -   `sep`\n    -   `into`\n\n### Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-101_344c674997c36db4c7fa4abe819ade3a'}\n\n```{.r .cell-code}\ntall |> \n  separate(col = \"measure\",\n           sep = \"_\",\n           into = c(\"timept\", \"measure\")\n           ) \n```\n:::\n\n\n### Result\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-102_c13854f15e41f4c37dfb79d750d03040'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 5\n   pat_id treatment timept measure score\n   <chr>  <chr>     <chr>  <chr>   <dbl>\n 1 001    upa       start  mes      3   \n 2 001    upa       end    mes      0   \n 3 001    upa       start  bss     75.9 \n 4 001    upa       end    bss      9.85\n 5 001    upa       start  emo     79.3 \n 6 001    upa       end    emo     39.8 \n 7 002    uste      start  mes      2   \n 8 002    uste      end    mes      1   \n 9 002    uste      start  bss     54.7 \n10 002    uste      end    bss     32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n### Alternative within pivot_longer\n\n-   You can do this *within* pivot_longer with one more argument (if you *read all of the pivot_longer documentation*)\n\n::: columns\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-103_e015e29a2ac441a56262de2fd21605e2'}\n\n```{.r .cell-code}\nwide |> \n  pivot_longer(cols = 3:8,\n    names_to = c(\"timept\", \"measure\"),\n    names_sep = \"_\",\n    values_to = \"score\")\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-104_9666c3a34a96cce8ec90850610bd1832'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 5\n   pat_id treatment timept measure score\n   <chr>  <chr>     <chr>  <chr>   <dbl>\n 1 001    upa       start  mes      3   \n 2 001    upa       end    mes      0   \n 3 001    upa       start  bss     75.9 \n 4 001    upa       end    bss      9.85\n 5 001    upa       start  emo     79.3 \n 6 001    upa       end    emo     39.8 \n 7 002    uste      start  mes      2   \n 8 002    uste      end    mes      1   \n 9 002    uste      start  bss     54.7 \n10 002    uste      end    bss     32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n:::\n\n:::\n\n:::\n\n\n\n## Pivoting Longer\n\n-   Your Turn with endo_data\n-   Measurements of Trans-Epithelial Electrical Resistance (TEER, the inverse of leakiness) in biopsies of 3 segments of intestine.\n-   This `could` be affected by portal hypertension in patients with liver cirrhosis\n- Let's find out!\n\n## Doing this At Home? Data load\n\n- Here is the code to load the data if you are doing this on a local computer. Use the clipboard icon at the top right to copy the code.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-105_229b096ca61e22105ad42b9f864f46b1'}\n\n```{.r .cell-code  code-fold=\"false\"}\nendo_data <- tibble::tribble(\n  ~pat_id, ~portal_htn, ~duod_teer, ~ileal_teer, ~colon_teer,\n  001, 1, 4.33, 14.57, 16.23,\n  002, 0, 11.67, 15.99, 18.97,\n  003, 1, 4.12, 13.77, 15.22,\n  004, 1, 4.62, 16.37, 18.12,\n  005, 0, 12.43, 15.84, 19.04,\n  006, 0, 13.05, 16.23, 18.81,\n  007, 0, 11.88, 15.72, 18.31,\n  008, 1, 4.87, 16.59, 18.77,\n  009, 1, 4.23, 15.04, 16.87,\n  010, 0, 12.77, 16.73, 19.12\n)\nendo_data\n```\n:::\n\n## Exercise PH1\n\n<br>\n\nComplete Data Cleaning Fundamentals Exercise PH1.\n\n- Do This in [Posit Cloud](https://posit.cloud/spaces/378150/join?access_code=7FQ1xLRyG4pLUwl3f3qhA2YxEtjw2hRpJvejGsd4) \n-   If you have the exercise done correctly, click on the Reactions tab in Zoom, and click to put the \"thumbs up\" emoji ðŸ‘ on your screen.\n\n-   If you are having trouble, click on the Reactions tab in Zoom, and click to put the \"raised hand\" emoji âœ‹ on your screen.\n\n[--\\> Take me to the exercise Solution \\<--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#ph1){target=\"_blank\"}\n\n<br>\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_8c738d95\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:3.5em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n\n\n## Pivoting Longer with endo_data\n\n::: panel-tabset\n### Dataset\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-107_fd598991d5c5d7437ef340f62631e4aa'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 5\n   pat_id portal_htn duod_teer ileal_teer colon_teer\n    <dbl>      <dbl>     <dbl>      <dbl>      <dbl>\n 1      1          1      4.33       14.6       16.2\n 2      2          0     11.7        16.0       19.0\n 3      3          1      4.12       13.8       15.2\n 4      4          1      4.62       16.4       18.1\n 5      5          0     12.4        15.8       19.0\n 6      6          0     13.0        16.2       18.8\n 7      7          0     11.9        15.7       18.3\n 8      8          1      4.87       16.6       18.8\n 9      9          1      4.23       15.0       16.9\n10     10          0     12.8        16.7       19.1\n```\n:::\n:::\n\n### Arguments\n\n-   What values do you want to use for these arguments to `pivot_longer`:\n    -   `cols`\n    -   `names_pattern` = \"(.+)\\_teer\"\n    -   `names_to`\n    -   `values_to`\n-   Note that we are giving you the correct value for `names_pattern`, which will ask for what we want - to keep the characters of the name (of whatever length) before \"\\_teer\"\n\n### Code\n\n-   Fill in the blanks to pivot this dataset to tall format, with columns for the intestinal location and the teer value.\n-   Note that we are giving you the correct answer for the `names_pattern` argument.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-108_5b225dcb82eb4135b67fb9014b2e054b'}\n\n```{.r .cell-code  code-fold=\"false\"}\nendo_data |> \n  pivot_longer(\n    cols = ___ ,\n    names_pattern = \"(.+)_teer\",\n    names_to =  ___ ,\n    values_to = ___\n  )\n```\n:::\n\n### Solution\n\n-   Fill in the blanks to pivot this dataset to tall format, with columns for the intestinal location and the teer value.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-109_6bb4ba2ac63bbd2eda589ecf49159c02'}\n\n```{.r .cell-code}\nendo_data |> \n  pivot_longer(\n    cols = \"duod_teer\":\"colon_teer\",\n    names_pattern = \"(.+)_teer\",\n    names_to = c(\"location\"),\n    values_to = \"teer\"\n  )\n```\n:::\n\n-   Run the code, and look at the resulting table. Use the clipboard icon at the top right to copy the code.\n\n### Result\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-110_8a5c190ab3aa5dc0fc963cb89b78ba5a'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 4\n   pat_id portal_htn location  teer\n    <dbl>      <dbl> <chr>    <dbl>\n 1      1          1 duod      4.33\n 2      1          1 ileal    14.6 \n 3      1          1 colon    16.2 \n 4      2          0 duod     11.7 \n 5      2          0 ileal    16.0 \n 6      2          0 colon    19.0 \n 7      3          1 duod      4.12\n 8      3          1 ileal    13.8 \n 9      3          1 colon    15.2 \n10      4          1 duod      4.62\n# â„¹ 20 more rows\n```\n:::\n:::\n-   Do you think that portal hypertension has an effect on TEER and (its inverse) epithelial leakiness?\n\n:::\n\n\n## Pivoting Wider\n\n::: panel-tabset\n\n### Tall messy_uc Data\n::: columns\n\n::: {.column width=\"50%\"}\n\n-   Wide data is less common, but sometimes needed for per-patient analysis\n-   Here we will convert the tall version of our selected messy_uc data back to wide.\n-   This is what the tall data look like\n\n:::\n\n\n::: {.column width=\"50%\"}\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-111_3cf8bfc2803f15f6d4abe2e86fc7d1f5'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 Ã— 4\n   pat_id treatment measure   score\n   <chr>  <chr>     <chr>     <dbl>\n 1 001    upa       start_mes  3   \n 2 001    upa       end_mes    0   \n 3 001    upa       start_bss 75.9 \n 4 001    upa       end_bss    9.85\n 5 001    upa       start_emo 79.3 \n 6 001    upa       end_emo   39.8 \n 7 002    uste      start_mes  2   \n 8 002    uste      end_mes    1   \n 9 002    uste      start_bss 54.7 \n10 002    uste      end_bss   32.7 \n# â„¹ 170 more rows\n```\n:::\n:::\n\n:::\n\n:::\n\n### Code to Pivot Wider\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-112_cdd776a93195e17618369ce1e6ba3979'}\n\n```{.r .cell-code}\ntall |> \n  pivot_wider(\n    id_cols = c(pat_id, treatment), # Variables not pivoted\n    names_from = measure, # will become column names\n    values_from = score # will become values\n  )\n```\n:::\n\n### Wider Result\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-113_7e699b82f70802664cc1556fea6936fa'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 Ã— 8\n   pat_id treatment start_mes end_mes start_bss end_bss start_emo end_emo\n   <chr>  <chr>         <dbl>   <dbl>     <dbl>   <dbl>     <dbl>   <dbl>\n 1 001    upa               3       0      75.9    9.85      79.3    39.8\n 2 002    uste              2       1      54.7   32.7       58.6    49.4\n 3 003    oza               1       1      28.5   28.5       32.2    35.9\n 4 004    upa               3       1      77.2   33.2       75.6    50.2\n 5 005    oza               3       2      78.8   56.8       74.3    65.0\n 6 006    uste              2       1      54.4   32.4       45.3    36.0\n 7 007    uste              3       2      79.7   57.7       66.6    57.8\n 8 008    oza               3       2      75.0   53.0       74.5    62.0\n 9 009    upa               2       0      53.1    9.06      50.0    27.8\n10 010    oza               3       1      78.9   34.9       72.5    45.9\n# â„¹ 20 more rows\n```\n:::\n:::\n\n:::\n\n## Longitudinal Data\n\n::: columns\n::: {.column width=\"60%\"}\n- Another set of data issues you may face is in data collected over time, when one of two things happen:\n  - You want to analyze data by day or month or year, and data in your Electronic Medical Record is collected and time-stamped by the `second`.\n  - You realize that some observations (on weekends) are missing, and you need to fill these dates in as missing, but you really don't want to do this by hand.\n- The {padr} package can help with these issues.\n\n:::\n::: {.column width=\"40%\"}\n![Longitudinal Data](images/long_data.png)\n:::\n:::\n\n\n## Thicken Date-Times with padr\n\n::: columns\n::: {.column width=\"55%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-114_51e665956bb294fcb975bb25a16d8acc'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 2\n  title                   time_stamp         \n  <chr>                   <dttm>             \n1 EMS: BACK PAINS/INJURY  2015-12-10 17:40:00\n2 EMS: DIABETIC EMERGENCY 2015-12-10 17:40:00\n3 Fire: GAS-ODOR/LEAK     2015-12-10 17:40:00\n4 EMS: CARDIAC EMERGENCY  2015-12-10 17:40:01\n5 EMS: DIZZINESS          2015-12-10 17:40:01\n6 EMS: HEAD INJURY        2015-12-10 17:40:01\n```\n:::\n:::\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"43%\"}\n-   The **emergency** data set in the {padr} package contains \\> 120K emergency calls from Montgomery County, PA over a period of \\~ 11 months.\n-   Each call has a title and a timestamp\n- We want to know in which months the emergency department should order an extra case of Narcan <br>(H: summer months?).\n:::\n:::\n\n\n\n## Thickening Time to a Usable Level\n\n::: panel-tabset\n### Starting Point\n\n-   The thicken function adds a column to a data frame that is of a higher interval than the original variable.\n- The intervals for {padr} are year, quarter, month, week, day, hour, min, and sec.\n-   The variable `time_stamp` has the interval of seconds\n-   We can thicken the data to the time  interval we need.\n-   Then we can count events by a usable unit of time\n\n### Original Data\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-115_54ad828ed66abb65092ab67aa2049f8c'}\n\n```{.r .cell-code}\nemergency |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 6\n    lat   lng   zip title                   time_stamp          twp             \n  <dbl> <dbl> <int> <chr>                   <dttm>              <chr>           \n1  40.3 -75.6 19525 EMS: BACK PAINS/INJURY  2015-12-10 17:40:00 NEW HANOVER     \n2  40.3 -75.3 19446 EMS: DIABETIC EMERGENCY 2015-12-10 17:40:00 HATFIELD TOWNSHâ€¦\n3  40.1 -75.4 19401 Fire: GAS-ODOR/LEAK     2015-12-10 17:40:00 NORRISTOWN      \n4  40.1 -75.3 19401 EMS: CARDIAC EMERGENCY  2015-12-10 17:40:01 NORRISTOWN      \n5  40.3 -75.6    NA EMS: DIZZINESS          2015-12-10 17:40:01 LOWER POTTSGROVE\n6  40.3 -75.3 19446 EMS: HEAD INJURY        2015-12-10 17:40:01 LANSDALE        \n```\n:::\n:::\n\n###  Thickened to Month\n-   We will thicken to month\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-116_973e9fd3bf8e804f279bcde8827c30f9'}\n\n```{.r .cell-code}\nemergency |> \n  thicken('month') |> \n  head() |> \n  select(-lat, -lng, -zip)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 4\n  title                   time_stamp          twp               time_stamp_month\n  <chr>                   <dttm>              <chr>             <date>          \n1 EMS: BACK PAINS/INJURY  2015-12-10 17:40:00 NEW HANOVER       2015-12-01      \n2 EMS: DIABETIC EMERGENCY 2015-12-10 17:40:00 HATFIELD TOWNSHIP 2015-12-01      \n3 Fire: GAS-ODOR/LEAK     2015-12-10 17:40:00 NORRISTOWN        2015-12-01      \n4 EMS: CARDIAC EMERGENCY  2015-12-10 17:40:01 NORRISTOWN        2015-12-01      \n5 EMS: DIZZINESS          2015-12-10 17:40:01 LOWER POTTSGROVE  2015-12-01      \n6 EMS: HEAD INJURY        2015-12-10 17:40:01 LANSDALE          2015-12-01      \n```\n:::\n:::\n\n### Thickened to Week\n-   We will thicken to week\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-117_06335e4e1b50a148d30bba9d38dd22c1'}\n\n```{.r .cell-code}\nemergency |> \n  thicken('week') |> \n  head() |> \n  select(-lat, -lng, -zip)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 4\n  title                   time_stamp          twp               time_stamp_week\n  <chr>                   <dttm>              <chr>             <date>         \n1 EMS: BACK PAINS/INJURY  2015-12-10 17:40:00 NEW HANOVER       2015-12-06     \n2 EMS: DIABETIC EMERGENCY 2015-12-10 17:40:00 HATFIELD TOWNSHIP 2015-12-06     \n3 Fire: GAS-ODOR/LEAK     2015-12-10 17:40:00 NORRISTOWN        2015-12-06     \n4 EMS: CARDIAC EMERGENCY  2015-12-10 17:40:01 NORRISTOWN        2015-12-06     \n5 EMS: DIZZINESS          2015-12-10 17:40:01 LOWER POTTSGROVE  2015-12-06     \n6 EMS: HEAD INJURY        2015-12-10 17:40:01 LANSDALE          2015-12-06     \n```\n:::\n:::\n\n:::\n\n\n## Thickening Time for a Monthly Plot\n\n::: panel-tabset\n### Goal\n\n-   The thicken function adds a column to a data frame that is of a higher interval than the original variable.\n-   The variable `time_stamp` has the interval of seconds\n-   We want to thicken this (time stamped) data to month, then select and count overdoses\n- This will set up the monthly overdose plot we want.\n\n### Code\n\n-   We will thicken to month\n-   Then count overdoses by month\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-118_3602b2faffe1ba3edd189d9b518b825e'}\n\n```{.r .cell-code}\nemergency |> \n  thicken('month') |> \n  group_by(time_stamp_month) |> \n  summarize(overdoses = sum(str_detect(title, \"OVERDOSE\"))) |> \n    select(time_stamp_month, overdoses) \n```\n:::\n\n### Result\n\n-   This lets us count events like overdoses by month with time_stamp_month.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-119_d76128d9d9acaa8b343e1cfde5ba420f'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 Ã— 2\n   time_stamp_month overdoses\n   <date>               <int>\n 1 2015-12-01              91\n 2 2016-01-01             135\n 3 2016-02-01             141\n 4 2016-03-01             161\n 5 2016-04-01             124\n 6 2016-05-01             149\n 7 2016-06-01             140\n 8 2016-07-01             147\n 9 2016-08-01             137\n10 2016-09-01             171\n11 2016-10-01              95\n```\n:::\n:::\n\n### Plot Monthly \n::: {.cell hash='index_cache/revealjs/unnamed-chunk-120_5d873a0ccd0109dfd32114d01c9231d2'}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-120-1.png){width=960}\n:::\n:::\n\n- When would you order extra cases of Narcan?\n\n:::\n\n\n\n## Padding unobserved dates (weekends?)\n\n::: columns\n::: {.column width=\"60%\"}\n-   The _pad()_ function allows you to fill in missing intervals.\n-   As an example, my hospital only runs fecal calprotectin tests on weekdays.\n-   This can lead to weird discontinuities in data over a weekend (Dec 3-4).\n-   No observations on weekend days/holidays.\n:::\n\n::: {.column width=\"40%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-121_7ba36f0ba2d68c67f8c1e7ac8b0b327a'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 14 Ã— 3\n   pat_id date         fcp\n   <chr>  <date>     <dbl>\n 1 001    2022-12-01  1574\n 2 001    2022-12-02  1323\n 3 001    2022-12-05   673\n 4 001    2022-12-06   314\n 5 001    2022-12-07   168\n 6 002    2022-11-30  1393\n 7 002    2022-12-01  1014\n 8 002    2022-12-02   812\n 9 002    2022-12-05   247\n10 002    2022-12-06   118\n11 003    2022-12-02   987\n12 003    2022-12-05   438\n13 003    2022-12-06   312\n14 003    2022-12-05   194\n```\n:::\n:::\n:::\n:::\n\n## Padding Unobserved Times\n\n::: panel-tabset\n### The Problem\n\n-   We can fill in (pad) the unobserved weekend days with the **pad()** function.\n\n### The Code\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-122_4c4750c7ad9d20d5188b0b1e45733529'}\n\n```{.r .cell-code}\nfcp |> \n  pad(group = \"pat_id\") |> # this adds lines for each missing day to the data\n  # by patient\n  print(n = 12)\n```\n:::\n\n### The Result\n\n::: columns\n::: {.column width=\"40%\"}\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-123_98877265fdad3d854f54fb32d4c70dfd'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 21 Ã— 3\n   pat_id date         fcp\n   <chr>  <date>     <dbl>\n 1 001    2022-12-01  1574\n 2 001    2022-12-02  1323\n 3 001    2022-12-03    NA\n 4 001    2022-12-04    NA\n 5 001    2022-12-05   673\n 6 001    2022-12-06   314\n 7 001    2022-12-07   168\n 8 002    2022-11-30  1393\n 9 002    2022-12-01  1014\n10 002    2022-12-02   812\n11 002    2022-12-03    NA\n12 002    2022-12-04    NA\n# â„¹ 9 more rows\n```\n:::\n:::\n:::\n\n::: {.column width=\"60%\"}\n-   New observations are created on the missing dates\n-   NAs are filled in for the missing FCPs, with one for each day and group (pat_id)\n- **pad()** fills in the missing pat_ids\n:::\n:::\n:::\n\n## Joining Data\n\n::: columns\n::: {.column width=\"60%\"}\n\n- Another data issue you will often face is that you have two interesting data sets, and that they would be more interesting if you could link the data in one to the data in the other.\n:::\n\n::: {.column width=\"40%\"}\n![Better Together: <br>Chocolate and Peanut Butter <br> (Datasets)](images/choc_pb.jpeg)\n:::\n\n:::\n\n## Joins of data from different sources\n\n::: columns\n::: {.column width=\"70%\"}\n\n-   We often collect data from different sources that we later want to join together for analysis\n    -   Data from your local Electronic Medical Record\n    -   Data from the CDC\n    -   Data from the US Census\n-   External data can illuminate our understanding of our local patient data\n:::\n\n::: {.column width=\"30%\"}\n![](images/LuxoJr_Lamp.webp)\n:::\n\n:::\n## Local Demographics with CDC SVI data\n\n::: panel-tabset\n### The Problem\n\n::: columns\n::: {.column width=\"60%\"}\n-   We have 2 datasets, one local Demographics and Census Tract, and one from the CDC that has values for Social Vulnerability Index by Census Tract\n-   We want to know if the SVI for the neighborhood of each patient influences health outcomes\n-   We need to `left_join` these datasets together by matching on the Census Tract\n:::\n\n::: {.column width=\"40%\"}\n![](images/joins.PNG)\n:::\n:::\n\n### The Data\n\n-   What is the common uniqid/key?\n\n::: columns\n::: {.column width=\"60%\"}\n-  Local EMR data (`demo`)\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-124_ff7a116f74e06088daf57c42d0313af3'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 4\n  pat_id name                 htn census_tract\n  <chr>  <chr>              <dbl>        <dbl>\n1 001    Arthur Blankenship     0  26161404400\n2 002    Britney Jonas          0  26161405100\n3 003    Sally Davis            1  26161402100\n4 004    Al Jones               0  26161403200\n5 005    Gary Hamill            1  26161405200\n6 006    Ken Bartoletti         0  26161404500\n7 007    Ike Gerhold            0  26161405600\n8 008    Tatiana Grant          0  26161404300\n9 009    Antione Delacroix      1  26161405500\n```\n:::\n:::\n:::\n\n::: {.column width=\"40%\"}\n-   `cdc`\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-125_2ea72aa7b802bac1bacc9be577700505'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 2\n  census_tract   svi\n         <dbl> <dbl>\n1  26161404400  0.12\n2  26161405100  0.67\n3  26161402100  0.43\n4  26161403200  0.07\n5  26161405200  0.71\n6  26161404500  0.23\n7  26161405600  0.27\n8  26161404300  0.21\n9  26161405500  0.62\n```\n:::\n:::\n:::\n:::\n\n### The Code\n\n-   Replace the generic arguments to the left_join function to join the demographic data (*demo*) on the left to add Social Vulnerability index (svi) from the *cdc* dataset on the RHS. Left join by census tract.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-126_79c69989b03e8c7522f0a97a811a93c0'}\n\n```{.r .cell-code}\nleft_join(dataset_x, dataset_y, by = \"key\")\n```\n:::\n\n### The Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-127_6fcfb8d953c43013a4527938bca7315f'}\n\n```{.r .cell-code}\nleft_join(demo, cdc, by = \"census_tract\")\n```\n:::\n\n### The Result\n- Now that the join is complete, you can ask your question:\n-   Is there an association between social vulnerability and hypertension?\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-128_3655a0a72eb01b884a2d28feb9176431'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 5\n  pat_id name                 htn census_tract   svi\n  <chr>  <chr>              <dbl>        <dbl> <dbl>\n1 001    Arthur Blankenship     0  26161404400  0.12\n2 002    Britney Jonas          0  26161405100  0.67\n3 003    Sally Davis            1  26161402100  0.43\n4 004    Al Jones               0  26161403200  0.07\n5 005    Gary Hamill            1  26161405200  0.71\n6 006    Ken Bartoletti         0  26161404500  0.23\n7 007    Ike Gerhold            0  26161405600  0.27\n8 008    Tatiana Grant          0  26161404300  0.21\n9 009    Antione Delacroix      1  26161405500  0.62\n```\n:::\n:::\n:::\n\n## Patient Demographics with Lab results (Your Turn to Join)\n\n::: columns\n::: {.column width=\"40%\"}\n-   We have some basic Patient Demographics in one table (*demo*)\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-129_ff7c37b6caee6f276533739332bda80d'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 3\n  pat_id name                 age\n  <chr>  <chr>              <dbl>\n1 001    Arthur Blankenship    67\n2 002    Britney Jonas         23\n3 003    Sally Davis           63\n4 004    Al Jones              44\n5 005    Gary Hamill           38\n6 006    Ken Bartoletti        33\n7 007    Ike Gerhold           52\n8 008    Tatiana Grant         42\n9 009    Antione Delacroix     27\n```\n:::\n:::\n:::\n\n::: {.column width=\"10%\"}\n:::\n\n::: {.column width=\"50%\" .fragment}\nand potassium levels and creatinine levels in 2 other tables (*pot* and *cr*)\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-130_dc7d640a08c74f70666d6568987829b0'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã— 2\n  pat_id     k\n  <chr>  <dbl>\n1 001      3.2\n2 002      3.7\n3 003      4.2\n4 004      4.4\n5 005      4.1\n```\n:::\n:::\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-131_4df2a866397a1641ae8741bd583c3e38'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã— 2\n  pat_id    cr\n  <chr>  <dbl>\n1 001      0.2\n2 002      0.5\n3 003      0.9\n4 004      1.5\n5 005      0.7\n```\n:::\n:::\n:::\n:::\n\n## Need to Load the Data?\n\nIf you are trying this on your local computer, copy the code below with the clipboard icon to get the data into your computer.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-132_9530a16384a0faa11a7a7073f6aac72b'}\n\n```{.r .cell-code}\ndemo <- tibble::tribble(\n  ~pat_id, ~name, ~age,\n  '001', \"Arthur Blankenship\", 67,\n  '002', \"Britney Jonas\", 23,\n  '003', \"Sally Davis\", 63,\n  '004', \"Al Jones\", 44,\n  '005', \"Gary Hamill\", 38,\n  '006', \"Ken Bartoletti\", 33,\n  '007', \"Ike Gerhold\", 52,\n  '008', \"Tatiana Grant\", 42,\n  '009', \"Antoine Delacroix\", 27,\n)\n\npot <- tibble::tribble(\n  ~pat_id, ~k,\n  '001', 3.2,\n  '002', 3.7,\n  '003', 4.2,\n  '004', 4.4,\n  '005', 4.1,\n  '006', 4.0,\n  '007', 3.6,\n  '008', 4.2,\n  '009', 4.9,\n)\n\ncr <- tibble::tribble(\n  ~pat_id, ~cr,\n  '001', 0.2,\n  '002', 0.5,\n  '003', 0.9,\n  '004', 1.5,\n  '005', 0.7,\n  '006', 0.9,\n  '007', 0.7,\n  '008', 1.0,\n  '009', 1.7,\n)\n```\n:::\n\n## Your Turn to Join\n\n-   We want to join the correct labs (9 rows each from the pot and cr datasets) to the correct patients.\n-   The unique identifier (called the uniqid or key or recordID) is pat_id.\n    + It only occurs once for each patient/row\n    + It appears in each table we want to join\n    + The pat_id is of the character type in each (a common downfall if one is character, one is numeric, but they **look** the same - but don't match)\n-   We want to start with demographics, then add datasets that match to the right.\n-   We will use *demo* as our base dataset on the left hand side (LHS), and first join the potassium (*pot*) results (RHS)\n\n## What the Left Join Looks Like\n- This is a *mutating* join - new variables from y are created/added to the LHS (x).\n\n   <div class=\"animations\"><img alt=\"gif here\" width=\"80%\" height=\"80%\" src=\"https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/left-join.gif\"> </div>  \n\n## Exercise PH2\n\n<br>\n\nComplete the Data Cleaning Fundamentals Exercise PH2.\n\n- Do This in [Posit Cloud](https://posit.cloud/spaces/378150/join?access_code=7FQ1xLRyG4pLUwl3f3qhA2YxEtjw2hRpJvejGsd4)\n\n-   If you have the exercise done correctly, click on the Reactions tab in Zoom, and click to put the \"thumbs up\" emoji ðŸ‘ on your screen.\n\n-   If you are having trouble, click on the Reactions tab in Zoom, and click to put the \"raised hand\" emoji âœ‹ on your screen.\n\n[--\\> Take me to the exercise Solution \\<--](https://shannonpileggi.github.io/rmedicine-data-cleaning-2023/exercises.html#ph2){target=\"_blank\"}\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div class=\"countdown\" id=\"timer_d67730e7\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;font-size:3.5em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n:::\n:::\n\n## Your Turn to Join\n\n::: panel-tabset\n### The Problem\n\n-   Joining *demo* to *pot* with a left_join\n-   left_join(`data_x`, `data_y`, by = `\"uniqid\"`)\n\n### The Code\n\n-   replace the generic arguments below with the correct ones to join *demo* to *pot* and produce *new_data*.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-134_6539a2e9882e927f2cdc826fca939a0e'}\n\n```{.r .cell-code  code-fold=\"false\"}\nnew_data <- left_join(data_x, data_y, by = \"uniqid\")\nnew_data\n```\n:::\n\nNote the syntax for identifying the `uniqid` on which to do the merge: `by = \"varname\"`\n\n### The Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-135_54aa40ed78a8efd33af537078106da70'}\n\n```{.r .cell-code  code-fold=\"true\"}\nnew_data <- left_join(demo, pot, by = \"pat_id\") \nnew_data\n```\n:::\n\n\n### The Result\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-136_f25a29d92b661842fd750eef80e777f1'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 4\n  pat_id name                 age     k\n  <chr>  <chr>              <dbl> <dbl>\n1 001    Arthur Blankenship    67   3.2\n2 002    Britney Jonas         23   3.7\n3 003    Sally Davis           63   4.2\n4 004    Al Jones              44   4.4\n5 005    Gary Hamill           38   4.1\n6 006    Ken Bartoletti        33   4  \n7 007    Ike Gerhold           52   3.6\n8 008    Tatiana Grant         42   4.2\n9 009    Antoine Delacroix     27   4.9\n```\n:::\n:::\n\n:::\n\n\n## Now add Creatinine (cr) to new_data\n\n::: panel-tabset\n### The Problem\n\n-   Joining new_data and cr with a left_join\n-   left_join(data_x, data_y, by = \"uniqid\")\n\n### The Code\n\n-   Replace the generic arguments with the correct ones to join new_data and cr and produce new_data2.\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-137_d287888b7fe943e4386ab8fac45f64b0'}\n\n```{.r .cell-code  code-fold=\"false\"}\nnew_data2 <- left_join(data_x, data_y, by = \"uniqid\")\nnew_data2\n```\n:::\n\n### The Solution\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-138_24c6362123d87f8449069c2070c5879b'}\n\n```{.r .cell-code  code-fold=\"true\"}\nnew_data2 <- left_join(new_data, cr, by = \"pat_id\")\nnew_data2\n```\n:::\n\n### The Result\n\n::: {.cell hash='index_cache/revealjs/unnamed-chunk-139_e34e8ed72e268c3298bf11a9e9123405'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 Ã— 5\n  pat_id name                 age     k    cr\n  <chr>  <chr>              <dbl> <dbl> <dbl>\n1 001    Arthur Blankenship    67   3.2   0.2\n2 002    Britney Jonas         23   3.7   0.5\n3 003    Sally Davis           63   4.2   0.9\n4 004    Al Jones              44   4.4   1.5\n5 005    Gary Hamill           38   4.1   0.7\n6 006    Ken Bartoletti        33   4     0.9\n7 007    Ike Gerhold           52   3.6   0.7\n8 008    Tatiana Grant         42   4.2   1  \n9 009    Antoine Delacroix     27   4.9   1.7\n```\n:::\n:::\n\n- Al has HTN and DM2\n- Antoine has early stage FSGS\n:::\n\n## Workhorse Joins\n\n-   *left_join* is your workhorse. Start with patient identifiers/uniqid and add data to the right side.\n-   Sometimes you will need to wrangle/process incoming data, then *right_join* it to the patient demographics\n\n::: columns\n\n::: {.column width=\"50%\"}\n   <div class=\"animations\"><img alt=\"gif here\" width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/left-join.gif\"> </div>  \n:::\n\n::: {.column width=\"50%\"}\n   <div class=\"animations\"><img alt=\"gif here\" width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/right-join.gif\"> </div>  \n:::\n\n:::\n\n## Fancy Joins\n\n-   There are multiple kinds of fancy joins (semi_join, anti_join, inner_join, full_join, union, intersect, setdiff) which come in handy once in a while.\n-   The many kinds of joins are all well explained [here](http://statseducation.com/Introduction-to-R/modules/tidy%20data/joins/#:~:text=semi_join(x%2C%20y)%3A%20Return,This%20is%20a%20filtering%20join.)\n\n::: columns\n\n::: {.column width=\"45%\"}\n- Subset your data (x), keeping only the ones (y=hospitalized) who were hospitalized.\n\n <div class=\"animations\"><img alt=\"gif here\" width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/semi-join.gif\"> </div>  \n:::\n\n::: {.column width=\"10%\"}\n:::\n\n::: {.column width=\"45%\"}\n- Subset your data (x), keeping only the ones (y = dead) who are NOT dead.\n\n <div class=\"animations\"><img alt=\"gif here\" width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/gadenbuie/tidyexplain/main/images/anti-join.gif\"> </div>  \n:::\n\n:::\n\n:::{.notes}\nThe joins shown below are *filtering* joins, which filter out rows in your x (LHS) dataset, but do not add any new variables.\n:::\n\n## Data Horror\n\n::: columns\n\n::: {.column width=\"50%\"}\nData So Messy, it Constitutes a Data Crime\n\n<br>\n![Messy](images/messy.png)\n\n<br>\nWhat Should You Do?\n:::\n\n::: {.column width=\"50%\"}\n<iframe src=\"https://giphy.com/embed/jquDWJfPUMCiI\" width=\"480\" height=\"428\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/scared-shocked-jquDWJfPUMCiI\"> The Horror! The Horror!</a></p>\n \n:::\n\n:::\n\n\n## Two Options\n\n::: columns\n\n::: {.column width=\"50%\"}\n1. You can find the person who collected/entered the data\n\n- If you don't correct this behavior now, this will torture _**many**_ future data analysts\n- Educate in this *teachable moment* about tidy data\n- Send them to watch Tidy Spreadsheets on YouTube [here](https://www.youtube.com/watch?v=9f-hpJbjKZo) to prevent this kind of Data Crime in the future.\n- **Improve** the world, one (now tidy) data collector at a time.\n:::\n\n::: {.column width=\"50%\" .fragment}\n2. There is no way to find the person who collected/entered the data\n\n- Pull out some advanced data cleaning packages made for this particular kind of mess\n  - {unpivotr}\n  - {tidyxl}\n  - {unheadr}\n- Watch the unpivotr/tidyxl 14 min video [here](https://www.youtube.com/watch?v=ShWxAqnY2YE)\n- Learn from a free e-book, [Spreadsheet Munging Strategies](https://nacnudus.github.io/spreadsheet-munging-strategies/)\n\n:::\n\n:::\n\n## Step by Step Cleaning - Stage 1\n\n- Import your data cleanly - skip rows, get headers\n- Explore your data\n- Remove empty rows & columns\n- Fix variable classes/types, check dates\n- Clean variable names \n- Create a codebook\n- Validate for missingness, outliers\n- Fix bad category values\n- Identify and consistently label missing values\n- Separate mixed (SBP/DBP) values, assign variable labels\n\n## Step by Step Cleaning - Stage 2 Wrangling\n\n- Let your Question define your Unit of Analysis\n- Pivot_longer or pivot_wider if needed\n- Thicken time, pad missing times if needed\n- Join to add new data if needed\n- Know what packages to use for data horrors\n  - unpivotr\n  - tidyxl\n  - unheadr\n\n\n## Thank you!\n\nðŸ™ [Click here to submit workshop feedback](https://forms.gle/kvEirN7sJmavem8q6){target=\"_blank\"}\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}